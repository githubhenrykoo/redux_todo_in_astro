name: Gemini Log Analysis

on:
  workflow_dispatch:
    inputs:
      days:
        description: 'Number of days of logs to analyze'
        required: false
        default: '1'
        type: string
      query:
        description: 'What would you like to ask about the logs?'
        required: false
        default: 'Summarize the main changes'
        type: string

jobs:
  analyze-logs:
    runs-on: ubuntu-latest
    environment: LLM_API_KEY
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        pip install --upgrade google-generativeai
        pip install python-dotenv

    - name: Analyze Logs with Gemini
      env:
        GOOGLE_API_KEY: ${{ secrets.GITHUBGEMINIKEY }}
      run: |
        cat << 'EOF' > analyze_logs.py
        import os
        import glob
        from datetime import datetime, timedelta
        import google.generativeai as genai

        # Configure Gemini with API key
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            print("Error: GOOGLE_API_KEY environment variable not set")
            exit(1)
            
        genai.configure(api_key=api_key)
        
        # Try to use the model directly without listing models
        try:
            model = genai.GenerativeModel('models/gemini-2.0-flash')
            print("Successfully initialized model: models/gemini-2.0-flash")
        except Exception as e:
            print(f"Failed to initialize primary model, trying fallback... Error: {str(e)}")
            try:
                model = genai.GenerativeModel('models/gemini-1.5-pro')
                print("Successfully initialized fallback model: models/gemini-1.5-pro")
            except Exception as e:
                print(f"Failed to initialize fallback model. Error: {str(e)}")
                exit(1)

        # Get the latest log file
        log_files = glob.glob('Docs/log/git-log-*.md')
        if not log_files:
            print("No log files found")
            exit(1)

        latest_log = max(log_files)
        with open(latest_log, 'r') as f:
            log_content = f.read()

        # Prepare the prompt
        query = '${{ github.event.inputs.query }}'
        prompt = f"""
        Analyze this git log and {query}:

        {log_content}

        Please provide:
        1. A summary of key changes
        2. Any patterns or trends you notice
        3. Recommendations if applicable
        """

        # Get Gemini's analysis
        try:
            response = model.generate_content(prompt)
            print("\n=== Gemini Analysis ===\n")
            print(response.text)
        except Exception as e:
            print(f"Error generating content: {str(e)}")
            print("Response details:", str(dir(e)))
            exit(1)
        EOF

        python analyze_logs.py

    - name: Save Analysis
      run: |
        # Create directory if it doesn't exist
        mkdir -p Docs/analysis
        # Save the analysis
        python analyze_logs.py > "Docs/analysis/gemini-analysis-$(date +%Y-%m-%d).md"

    - name: Commit Analysis
      run: |
        # Ensure directory exists and file was created
        if [ -f "Docs/analysis/gemini-analysis-$(date +%Y-%m-%d).md" ]; then
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add "Docs/analysis/gemini-analysis-$(date +%Y-%m-%d).md"
          git commit -m "docs: add Gemini analysis for $(date +%Y-%m-%d)" || echo "No changes to commit"
          git push origin HEAD:main
        else
          echo "Analysis file not found, skipping commit"
          exit 1
        fi