name: Git Log and Analysis

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      days:
        description: 'Number of days to look back'
        required: false
        default: '1'
        type: string
      query:
        description: 'What would you like to ask about the logs?'
        required: false
        default: 'Summarize the main changes'
        type: string

permissions:
  contents: write

jobs:
  generate-and-analyze:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        pip install --upgrade google-generativeai
        pip install python-dotenv

    - name: Generate Git Log
      run: |
        # Import name mapping
        cat << 'EOF' > get_name.py
        from Docs.config.name_mapping import NAME_MAPPING

        def get_real_name(username):
            return NAME_MAPPING.get(username, username)
        EOF

        # Generate main log file
        echo "# Git Activity Log" > "Docs/log/git-log-$(date +%Y-%m-%d).md"
        echo "Generated at: $(date)" >> "Docs/log/git-log-$(date +%Y-%m-%d).md"
        
        # Get first and last commit hashes
        FIRST_COMMIT=$(git log --since="${{ github.event.inputs.days || 1 }} days ago" --reverse --format="%H" | head -n 1)
        LAST_COMMIT=$(git log --since="${{ github.event.inputs.days || 1 }} days ago" --format="%H" | head -n 1)
        
        # Generate main diff log
        echo "## Changes Between First and Last Commits" >> "Docs/log/git-log-$(date +%Y-%m-%d).md"
        echo "\`\`\`diff" >> "Docs/log/git-log-$(date +%Y-%m-%d).md"
        if [ ! -z "$FIRST_COMMIT" ] && [ ! -z "$LAST_COMMIT" ]; then
          git diff $FIRST_COMMIT..$LAST_COMMIT -- . ':!node_modules' ':!package-lock.json' >> "Docs/log/git-log-$(date +%Y-%m-%d).md"
        else
          echo "No commits found in the specified timeframe" >> "Docs/log/git-log-$(date +%Y-%m-%d).md"
        fi
        echo "\`\`\`" >> "Docs/log/git-log-$(date +%Y-%m-%d).md"
        
        # Generate per-user logs with real names
        for author in $(git log --since="${{ github.event.inputs.days || 1 }} days ago" --format="%ae" | sort -u); do
          username=$(echo "$author" | cut -d@ -f1)
          real_name=$(python3 -c "from get_name import get_real_name; print(get_real_name('$username'))")
          mkdir -p "Docs/log/users/$username"
          
          echo "# Git Activity Log - $real_name" > "Docs/log/users/$username/git-log-$(date +%Y-%m-%d).md"
          echo "Generated at: $(date)" >> "Docs/log/users/$username/git-log-$(date +%Y-%m-%d).md"
          echo "## Changes by $real_name" >> "Docs/log/users/$username/git-log-$(date +%Y-%m-%d).md"
          echo "\`\`\`diff" >> "Docs/log/users/$username/git-log-$(date +%Y-%m-%d).md"
          git log --since="${{ github.event.inputs.days || 1 }} days ago" --author="$author" --patch --no-merges -- . ':!node_modules' ':!package-lock.json' >> "Docs/log/users/$username/git-log-$(date +%Y-%m-%d).md"
          echo "\`\`\`" >> "Docs/log/users/$username/git-log-$(date +%Y-%m-%d).md"
        done

    - name: Analyze Logs with Gemini
      env:
        GOOGLE_API_KEY: AIzaSyBZ52gRnYBjfyyh4jiEWscKoRfTx-j4YEQ
      run: |
        cat << 'EOF' > analyze_logs.py
        import os
        import glob
        import time
        from datetime import datetime
        import google.generativeai as genai
        from Docs.config.prompts.group_analysis import GROUP_ANALYSIS_PROMPT
        from Docs.config.prompts.user_analysis import USER_ANALYSIS_PROMPT
        from Docs.config.prompts.summary import SUMMARY_PROMPT

        def generate_with_retry(model, prompt, max_retries=3, initial_delay=5):
            for attempt in range(max_retries):
                try:
                    if attempt > 0:
                        time.sleep(initial_delay * (2 ** attempt))  # Exponential backoff
                    response = model.generate_content(prompt)
                    return response.text
                except exceptions.ResourceExhausted:
                    if attempt == max_retries - 1:
                        raise
                    print(f"Rate limit hit, retrying in {initial_delay * (2 ** (attempt + 1))} seconds...")
                except Exception as e:
                    print(f"Error: {str(e)}")
                    if attempt == max_retries - 1:
                        raise
            return None

        def analyze_content(model, content, query, prompt_template):
            chunks = chunk_content(content)
            all_analyses = []
            
            for i, chunk in enumerate(chunks, 1):
                if i > 1:
                    time.sleep(5)  # Increased delay between requests
                
                chunk_prompt = prompt_template.format(
                    query=query,
                    content=chunk,
                    chunk_info=f"(Part {i} of {len(chunks)})" if len(chunks) > 1 else ""
                )
                
                analysis = generate_with_retry(model, chunk_prompt)
                if analysis:
                    all_analyses.append(analysis)
            
            if len(all_analyses) > 1:
                time.sleep(5)  # Increased delay before summary
                summary_prompt = SUMMARY_PROMPT.format(content='\n\n'.join(all_analyses))
                return generate_with_retry(model, summary_prompt)
            
            return all_analyses[0] if all_analyses else "Analysis failed due to API limitations"

        def chunk_content(content, max_chars=400000):  # Approximately 100k tokens
            lines = content.split('\n')
            chunks = []
            current_chunk = []
            current_size = 0
            
            for line in lines:
                line_size = len(line) + 1  # +1 for newline
                if current_size + line_size > max_chars and current_chunk:
                    chunks.append('\n'.join(current_chunk))
                    current_chunk = [line]
                    current_size = line_size
                else:
                    current_chunk.append(line)
                    current_size += line_size
            
            if current_chunk:
                chunks.append('\n'.join(current_chunk))
            return chunks

        # Configure Gemini
        genai.configure(api_key="AIzaSyBZ52gRnYBjfyyh4jiEWscKoRfTx-j4YEQ")
        model = genai.GenerativeModel('gemini-2.0-flash')

        # Analyze group log
        log_files = glob.glob('Docs/log/git-log-*.md')
        if log_files:
            latest_log = max(log_files)
            with open(latest_log, 'r') as f:
                group_content = f.read()

            query = '${{ github.event.inputs.query }}'
            analysis = analyze_content(model, group_content, query, GROUP_ANALYSIS_PROMPT)
            os.makedirs('Docs/analysis/group', exist_ok=True)
            with open(f'Docs/analysis/group/team-analysis-{datetime.now().strftime("%Y-%m-%d")}.md', 'w') as f:
                f.write(f"# Team Analysis\nGenerated at: {datetime.now()}\n\n{analysis}")

        # Analyze individual user logs
        user_dirs = glob.glob('Docs/log/users/*/')
        for user_dir in user_dirs:
            username = os.path.basename(os.path.dirname(user_dir))
            if username == '.gitkeep':
                continue

            user_logs = glob.glob(f'{user_dir}git-log-*.md')
            if user_logs:
                latest_user_log = max(user_logs)
                with open(latest_user_log, 'r') as f:
                    user_content = f.read()

                response = model.generate_content(USER_ANALYSIS_PROMPT.format(
                    query=query,
                    content=user_content
                ))
                os.makedirs(f'Docs/analysis/users/{username}', exist_ok=True)
                with open(f'Docs/analysis/users/{username}/analysis-{datetime.now().strftime("%Y-%m-%d")}.md', 'w') as f:
                    f.write(f"# Developer Analysis - {username}\nGenerated at: {datetime.now()}\n\n{response.text}")
        EOF

        python analyze_logs.py

    - name: Refine Analysis
      env:
        GOOGLE_API_KEY: AIzaSyBZ52gRnYBjfyyh4jiEWscKoRfTx-j4YEQ
      run: |
        cat << 'EOF' > refine_analysis.py
        import os
        import glob
        import time
        from datetime import datetime
        import google.generativeai as genai
        from google.api_core import exceptions
        from Docs.config.prompts.group_critique import GROUP_CRITIQUE_PROMPT
        from Docs.config.prompts.user_critique import USER_CRITIQUE_PROMPT
        from Docs.config.prompts.refinement import REFINEMENT_PROMPT

        def generate_with_retry(model, prompt, max_retries=3, initial_delay=5):
            for attempt in range(max_retries):
                try:
                    if attempt > 0:
                        time.sleep(initial_delay * (2 ** attempt))
                    response = model.generate_content(prompt)
                    return response.text
                except exceptions.ResourceExhausted:
                    if attempt == max_retries - 1:
                        raise
                    print(f"Rate limit hit, retrying in {initial_delay * (2 ** (attempt + 1))} seconds...")
                except Exception as e:
                    print(f"Error: {str(e)}")
                    if attempt == max_retries - 1:
                        raise
            return None

        def refine_analysis(model, analysis_content, critique_prompt):
            # Generate critique
            critique = generate_with_retry(model, critique_prompt)
            if not critique:
                return analysis_content

            # Use critique to refine
            refined = generate_with_retry(
                model,
                REFINEMENT_PROMPT.format(
                    analysis_content=analysis_content,
                    critique=critique
                )
            )
            return refined if refined else analysis_content

        # Configure Gemini
        genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
        model = genai.GenerativeModel('gemini-2.0-flash')

        # Refine group analysis
        group_files = glob.glob('Docs/analysis/group/team-analysis-*.md')
        if group_files:
            latest_analysis = max(group_files)
            with open(latest_analysis, 'r') as f:
                analysis_content = f.read()
            
            refined_analysis = refine_analysis(model, analysis_content, GROUP_CRITIQUE_PROMPT)
            if refined_analysis:
                refined_path = latest_analysis.replace('team-analysis-', 'refined-team-analysis-')
                with open(refined_path, 'w') as f:
                    f.write(f"# Refined Team Analysis\nGenerated at: {datetime.now()}\n\n{refined_analysis}")

        # Refine individual analyses
        user_dirs = glob.glob('Docs/analysis/users/*/')
        for user_dir in user_dirs:
            username = os.path.basename(os.path.dirname(user_dir))
            if username == '.gitkeep':
                continue

            analysis_files = glob.glob(f'{user_dir}analysis-*.md')
            if analysis_files:
                latest_analysis = max(analysis_files)
                with open(latest_analysis, 'r') as f:
                    analysis_content = f.read()

                refined_analysis = refine_analysis(model, analysis_content, USER_CRITIQUE_PROMPT)
                if refined_analysis:
                    refined_path = latest_analysis.replace('analysis-', 'refined-analysis-')
                    with open(refined_path, 'w') as f:
                        f.write(f"# Refined Developer Analysis - {username}\nGenerated at: {datetime.now()}\n\n{refined_analysis}")
        EOF

        python refine_analysis.py

    - name: Commit and Push Changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Stage all changes
        git add "Docs/log/" "Docs/analysis/" "analyze_logs.py"
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
          exit 0
        fi
        
        # Stash any uncommitted changes
        git stash
        
        # Pull latest changes with rebase strategy
        git pull --rebase origin main
        
        # Pop stashed changes
        git stash pop
        
        # Commit changes
        git commit -m "docs: update git log and analysis for $(date +%Y-%m-%d)"
        
        # Push changes with force-with-lease for safety
        git push origin main --force-with-lease

  refine-meta-template:
    needs: generate-and-analyze
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        pip install --upgrade google-generativeai
        pip install python-dotenv

    - name: Refine Meta Template
      env:
        GOOGLE_API_KEY: AIzaSyBZ52gRnYBjfyyh4jiEWscKoRfTx-j4YEQ
      run: |
        cat << 'EOF' > refine_template.py
        import os
        import time
        from datetime import datetime
        import google.generativeai as genai
        from google.api_core import exceptions
        from Docs.config.prompts.meta_template import META_TEMPLATE_PROMPT, VALIDATION_CRITERIA, SECTION_PROMPTS

        def generate_with_retry(model, prompt, max_retries=3, initial_delay=5):
            for attempt in range(max_retries):
                try:
                    if attempt > 0:
                        time.sleep(initial_delay * (2 ** attempt))
                    response = model.generate_content(prompt)
                    return response.text
                except Exception as e:
                    print(f"Error: {str(e)}")
                    if attempt == max_retries - 1:
                        raise
            return None

        def refine_template(model, template_content):
            # Use the existing template structure for refinement
            refinement_content = META_TEMPLATE_PROMPT.format(content=template_content)
            return generate_with_retry(model, refinement_content)

        # Configure Gemini
        genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
        model = genai.GenerativeModel('gemini-2.0-flash')

        # Read current template
        with open('Docs/config/prompts/meta_template.py', 'r') as f:
            current_template = f.read()

        # Generate refinements
        refined_content = refine_template(model, current_template)
        
        if refined_content:
            # Create backup of current template
            backup_path = f'Docs/config/prompts/backups/meta_template_{datetime.now().strftime("%Y%m%d_%H%M%S")}.py'
            os.makedirs(os.path.dirname(backup_path), exist_ok=True)
            with open(backup_path, 'w') as f:
                f.write(current_template)

            # Write refined template
            with open('Docs/config/prompts/meta_template.py', 'w') as f:
                f.write(refined_content)

            # Generate changelog using the template structure
            changelog_path = 'Docs/config/prompts/changelog.md'
            with open(changelog_path, 'a') as f:
                f.write(f"\n\n## Template Refinement - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("Changes made by Gemini AI:\n")
                f.write(generate_with_retry(model, META_TEMPLATE_PROMPT.format(
                    content=f"Compare these versions and list key changes:\n\nOriginal:\n{current_template}\n\nRefined:\n{refined_content}"
                )))
        EOF

        python refine_template.py

    - name: Commit and Push Changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add "Docs/config/prompts/"
        git commit -m "refactor: refine meta template structure $(date +%Y-%m-%d)" || echo "No changes to commit"
        git pull --rebase origin main
        git push origin HEAD:main