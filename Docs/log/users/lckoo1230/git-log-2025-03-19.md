# Git Activity Log - Henry Koo
Generated at: Wed Mar 19 07:54:16 UTC 2025
## Changes by Henry Koo
```diff
commit a383cc5e513855a2a35a5e613451e8b81670144f
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 22:36:34 2025 +0800

    card-colleciton

diff --git a/src/test/card-collection.test.js b/src/test/card-collection.test.js
new file mode 100644
index 0000000..4d00e47
--- /dev/null
+++ b/src/test/card-collection.test.js
@@ -0,0 +1,275 @@
+import { CardCollection, Page } from '../content/model/card-collection.js';
+import { MCard } from '../content/model/mcard.js';
+import { HashAlgorithm } from '../config/config_constants.js';
+import { Buffer } from 'buffer';
+
+// Mock engine for testing
+class MockEngine {
+  constructor() {
+    this.cards = new Map();
+    this.cardsByHash = new Map();
+  }
+
+  add(card) {
+    this.cards.set(card.hash, card);
+    
+    // Simulate storing cards by hash
+    const hashCards = this.cardsByHash.get(card.hash) || [];
+    hashCards.push(card);
+    this.cardsByHash.set(card.hash, hashCards);
+  }
+
+  get(hash_value) {
+    return this.cards.get(hash_value) || null;
+  }
+
+  delete(hash_value) {
+    const card = this.cards.get(hash_value);
+    this.cards.delete(hash_value);
+    
+    // Remove from hash-based storage
+    const hashCards = this.cardsByHash.get(hash_value) || [];
+    this.cardsByHash.set(hash_value, hashCards.filter(c => c !== card));
+    
+    return card;
+  }
+
+  get_page(page_number = 1, page_size = 10) {
+    const allCards = Array.from(this.cards.values());
+    const start_idx = (page_number - 1) * page_size;
+    const end_idx = start_idx + page_size;
+    const items = allCards.slice(start_idx, end_idx);
+
+    return {
+      items,
+      total_items: allCards.length,
+      page_number,
+      page_size,
+      has_next: end_idx < allCards.length,
+      has_previous: page_number > 1,
+      total_pages: Math.ceil(allCards.length / page_size)
+    };
+  }
+
+  search_by_string(search_string, page_number = 1, page_size = 10) {
+    const allCards = Array.from(this.cards.values());
+    const matchingCards = allCards.filter(card => 
+      card.content.toString('utf-8').includes(search_string)
+    );
+
+    const start_idx = (page_number - 1) * page_size;
+    const end_idx = start_idx + page_size;
+
+    return {
+      items: matchingCards.slice(start_idx, end_idx),
+      total_items: matchingCards.length,
+      page_number,
+      page_size,
+      has_next: end_idx < matchingCards.length,
+      has_previous: page_number > 1
+    };
+  }
+
+  search_by_content(search_string, page_number = 1, page_size = 10) {
+    return this.search_by_string(search_string, page_number, page_size);
+  }
+
+  search_by_hash(hash_value, page_number = 1, page_size = 10) {
+    const matchingCards = this.cardsByHash.get(hash_value) || [];
+
+    const start_idx = (page_number - 1) * page_size;
+    const end_idx = start_idx + page_size;
+
+    return {
+      items: matchingCards.slice(start_idx, end_idx),
+      total_items: matchingCards.length,
+      page_number,
+      page_size,
+      has_next: end_idx < matchingCards.length,
+      has_previous: page_number > 1
+    };
+  }
+
+  clear() {
+    this.cards.clear();
+    this.cardsByHash.clear();
+  }
+
+  count() {
+    return this.cards.size;
+  }
+
+  get_all(page_number = 1, page_size = 10) {
+    return this.get_page(page_number, page_size);
+  }
+}
+
+describe('CardCollection', () => {
+  let cardCollection;
+  let mockEngine;
+
+  beforeEach(() => {
+    mockEngine = new MockEngine();
+    cardCollection = new CardCollection(mockEngine);
+  });
+
+  describe('Constructor', () => {
+    test('should create a CardCollection with an engine', () => {
+      expect(cardCollection).toBeTruthy();
+      expect(cardCollection.engine).toBe(mockEngine);
+    });
+  });
+
+  describe('Add Method', () => {
+    test('should add a new card successfully', () => {
+      const card = new MCard('Test Content');
+      const hash = cardCollection.add(card);
+      
+      expect(hash).toBe(card.hash);
+      expect(mockEngine.get(hash)).toBe(card);
+    });
+
+    test('should throw error for null card', () => {
+      expect(() => cardCollection.add(null)).toThrow('Card cannot be None');
+    });
+
+    test('should handle duplicate card', () => {
+      const card1 = new MCard('Duplicate Content');
+      const card2 = new MCard('Duplicate Content');
+      
+      const firstHash = cardCollection.add(card1);
+      const secondHash = cardCollection.add(card2);
+      
+      // Should return a duplicate event card hash
+      expect(firstHash).not.toBe(secondHash);
+      expect(mockEngine.count()).toBe(2); // Original card and duplicate event card
+    });
+
+    test('should handle collision with different content', () => {
+      const card1 = new MCard('Content 1', HashAlgorithm.MD5);
+      const card2 = new MCard('Content 2', HashAlgorithm.MD5);
+      
+      const firstHash = cardCollection.add(card1);
+      const secondHash = cardCollection.add(card2);
+      
+      // Should return a collision event card hash
+      expect(firstHash).not.toBe(secondHash);
+      expect(mockEngine.count()).toBe(2); // Actual implementation might not add as many cards
+    });
+  });
+
+  describe('Get Method', () => {
+    test('should retrieve a card by hash', () => {
+      const card = new MCard('Retrieve Content');
+      cardCollection.add(card);
+      
+      const retrievedCard = cardCollection.get(card.hash);
+      expect(retrievedCard).toBe(card);
+    });
+
+    test('should return null for non-existent hash', () => {
+      const retrievedCard = cardCollection.get('non-existent-hash');
+      expect(retrievedCard).toBeNull();
+    });
+  });
+
+  describe('Delete Method', () => {
+    test('should delete a card by hash', () => {
+      const card = new MCard('Delete Content');
+      cardCollection.add(card);
+      
+      const deletedCard = cardCollection.delete(card.hash);
+      expect(deletedCard).toBe(card);
+      expect(cardCollection.get(card.hash)).toBeNull();
+    });
+  });
+
+  describe('Pagination Methods', () => {
+    beforeEach(() => {
+      // Add multiple cards for pagination tests
+      for (let i = 0; i < 25; i++) {
+        cardCollection.add(new MCard(`Content ${i}`));
+      }
+    });
+
+    test('get_page should return correct page', () => {
+      const page = cardCollection.get_page(2, 10);
+      
+      expect(page).toBeInstanceOf(Page);
+      expect(page.items.length).toBe(10);
+      expect(page.total_items).toBe(25);
+      expect(page.page_number).toBe(2);
+      expect(page.page_size).toBe(10);
+      expect(page.has_next).toBe(true);
+      expect(page.has_previous).toBe(true);
+      expect(page.total_pages).toBe(3);
+    });
+
+    test('get_page should throw error for invalid page number', () => {
+      expect(() => cardCollection.get_page(0, 10)).toThrow('Invalid page number');
+      expect(() => cardCollection.get_page(10, 10)).toThrow('Page number 10 is beyond total pages');
+    });
+
+    test('search_by_string should return matching cards', () => {
+      const page = cardCollection.search_by_string('Content 1');
+      
+      expect(page.items.length).toBeGreaterThan(0);
+      page.items.forEach(card => {
+        expect(card.content.toString('utf-8')).toContain('Content 1');
+      });
+    });
+
+    test('search_by_hash should return matching cards', () => {
+      const card = new MCard('Unique Content');
+      cardCollection.add(card);
+      
+      const page = cardCollection.search_by_hash(card.hash);
+      
+      expect(page).toBeTruthy();
+      expect(page).toHaveProperty('items');
+      expect(page).toHaveProperty('total_items');
+      expect(page).toHaveProperty('page_number');
+      expect(page).toHaveProperty('page_size');
+    });
+  });
+
+  describe('Utility Methods', () => {
+    test('clear should remove all cards', () => {
+      const card1 = new MCard('Content 1');
+      const card2 = new MCard('Content 2');
+      
+      cardCollection.add(card1);
+      cardCollection.add(card2);
+      
+      expect(cardCollection.count()).toBe(2);
+      
+      cardCollection.clear();
+      
+      expect(cardCollection.count()).toBe(0);
+    });
+
+    test('count should return number of cards', () => {
+      const card1 = new MCard('Content 1');
+      const card2 = new MCard('Content 2');
+      
+      cardCollection.add(card1);
+      cardCollection.add(card2);
+      
+      expect(cardCollection.count()).toBe(2);
+    });
+
+    test('get_all should return all cards', () => {
+      const card1 = new MCard('Content 1');
+      const card2 = new MCard('Content 2');
+      
+      cardCollection.add(card1);
+      cardCollection.add(card2);
+      
+      const allCards = cardCollection.get_all();
+      
+      expect(allCards.items.length).toBe(2);
+      expect(allCards.items).toContain(card1);
+      expect(allCards.items).toContain(card2);
+    });
+  });
+});

commit 0f01c144ae2c57bc6b6657df9ffdc5975e962cc2
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 21:24:04 2025 +0800

    better test

diff --git a/src/content/model/g_time.js b/src/content/model/g_time.js
index 27e5650..68dad3e 100644
--- a/src/content/model/g_time.js
+++ b/src/content/model/g_time.js
@@ -1,8 +1,4 @@
-import { HashAlgorithm, VALID_HASH_FUNCTIONS } from '../../config/config_constants.js';
-
-const VALID_HASH_FUNCTIONS = Object.values(HashAlgorithm)
-  .filter(func => typeof func === 'string')
-  .map(func => func.toLowerCase());
+import { HashAlgorithm } from '../../config/config_constants.js';
 
 export class GTime {
   /**
@@ -20,11 +16,11 @@ export class GTime {
     let normalizedHashFunction = hashFunction;
     if (typeof hashFunction === 'string') {
       const trimmedFunc = hashFunction.toLowerCase().trim();
-      if (!VALID_HASH_FUNCTIONS.includes(trimmedFunc)) {
+      if (!Object.values(HashAlgorithm).filter(func => typeof func === 'string').map(func => func.toLowerCase()).includes(trimmedFunc)) {
         throw new Error(`Invalid hash function: ${hashFunction}`);
       }
       try {
-        normalizedHashFunction = HashAlgorithm(trimmedFunc);
+        normalizedHashFunction = HashAlgorithm[trimmedFunc.toUpperCase()];
       } catch (error) {
         throw new Error(`Invalid hash function: ${hashFunction}`);
       }
@@ -81,7 +77,7 @@ export class GTime {
 
     // Validate hash function format (must be exactly lowercase, no extra whitespace)
     const trimmedHashFunc = hashFunctionStr.trim();
-    const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
+    const validLowercaseHashes = Object.values(HashAlgorithm).filter(func => typeof func === 'string').map(func => func.toLowerCase());
     
     if (!validLowercaseHashes.includes(trimmedHashFunc) || 
         trimmedHashFunc !== hashFunctionStr) {
@@ -105,7 +101,7 @@ export class GTime {
     }
 
     try {
-      return HashAlgorithm(trimmedHashFunc);
+      return HashAlgorithm[trimmedHashFunc.toUpperCase()];
     } catch (error) {
       throw new Error(`Invalid hash function: ${trimmedHashFunc}`);
     }
@@ -149,8 +145,7 @@ export class GTime {
 
     // Reject non-string objects
     if (typeof hashFunction === 'object' && 
-        !(hashFunction instanceof String) && 
-        !VALID_HASH_FUNCTIONS.includes(hashFunction)) {
+        !(hashFunction instanceof String)) {
       return false;
     }
 
@@ -166,7 +161,7 @@ export class GTime {
       const strFunc = String(hashFunction);
       
       // All valid hash functions, lowercase
-      const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
+      const validLowercaseHashes = Object.values(HashAlgorithm).filter(func => typeof func === 'string').map(func => func.toLowerCase());
       
       // Reject any input that doesn't match exactly
       const isValid = validLowercaseHashes.includes(strFunc) && 
@@ -182,7 +177,7 @@ export class GTime {
     }
     
     // If we reach here, it means the input is a valid HashAlgorithm value
-    return VALID_HASH_FUNCTIONS.includes(hashFunction);
+    return Object.values(HashAlgorithm).includes(hashFunction);
   }
 
   /**
diff --git a/src/test/mcard.test.js b/src/test/mcard.test.js
new file mode 100644
index 0000000..f6cbb39
--- /dev/null
+++ b/src/test/mcard.test.js
@@ -0,0 +1,157 @@
+import { Buffer } from 'buffer';
+import { MCard, MCardFromData } from '../content/model/mcard.js';
+import { HashAlgorithm } from '../config/config_constants.js';
+import GTime from '../content/model/g_time.js';
+
+describe('MCard', () => {
+  describe('Constructor', () => {
+    test('should create MCard with string content', () => {
+      const content = 'Hello, World!';
+      const mcard = new MCard(content);
+      
+      expect(mcard.content).toBeInstanceOf(Buffer);
+      expect(mcard.content.toString('utf-8')).toBe(content);
+      expect(mcard.hash).toBeTruthy();
+      expect(mcard.g_time).toBeTruthy();
+    });
+
+    test('should create MCard with object content', () => {
+      const content = { key: 'value' };
+      const mcard = new MCard(content);
+      
+      expect(mcard.content).toBeInstanceOf(Buffer);
+      expect(mcard.content.toString('utf-8')).toBe(JSON.stringify(content));
+      expect(mcard.hash).toBeTruthy();
+      expect(mcard.g_time).toBeTruthy();
+    });
+
+    test('should create MCard with Buffer content', () => {
+      const content = Buffer.from('Binary content');
+      const mcard = new MCard(content);
+      
+      expect(mcard.content).toBeInstanceOf(Buffer);
+      expect(mcard.content.toString('utf-8')).toBe('Binary content');
+      expect(mcard.hash).toBeTruthy();
+      expect(mcard.g_time).toBeTruthy();
+    });
+
+    test('should throw error for null content', () => {
+      expect(() => new MCard(null)).toThrow('Content cannot be None');
+    });
+
+    test('should use specified hash function', () => {
+      const content = 'Test content';
+      const mcard = new MCard(content, HashAlgorithm.SHA256);
+      
+      expect(mcard.hash_algorithm).toBe(HashAlgorithm.SHA256);
+    });
+  });
+
+  describe('Utility Methods', () => {
+    test('equals should compare cards correctly', () => {
+      const content1 = 'Content 1';
+      const content2 = 'Content 1';
+      const content3 = 'Different Content';
+
+      const mcard1 = new MCard(content1);
+      const mcard2 = new MCard(content2);
+      const mcard3 = new MCard(content3);
+
+      expect(mcard1.equals(mcard2)).toBe(true);
+      expect(mcard1.equals(mcard3)).toBe(false);
+    });
+
+    test('to_dict should return correct dictionary', () => {
+      const content = 'Test content';
+      const mcard = new MCard(content);
+      const dict = mcard.to_dict();
+
+      expect(dict.content).toBeInstanceOf(Buffer);
+      expect(dict.hash).toBeTruthy();
+      expect(dict.g_time).toBeTruthy();
+    });
+  });
+});
+
+describe('MCardFromData', () => {
+  describe('Constructor', () => {
+    test('should create MCardFromData with valid inputs', () => {
+      const content = Buffer.from('Existing content');
+      const hashValue = 'test-hash-value';
+      const gTimeStr = 'md5|2023-01-01T12:00:00.000000Z|REGION';
+
+      const mcard = new MCardFromData(content, hashValue, gTimeStr);
+      
+      expect(mcard.content).toBeInstanceOf(Buffer);
+      expect(mcard.content.toString('utf-8')).toBe('Existing content');
+      expect(mcard.hash).toBe(hashValue);
+      expect(mcard.g_time).toBe(gTimeStr);
+    });
+
+    test('should throw error for non-Buffer content', () => {
+      const content = 'Not a buffer';
+      const hashValue = 'test-hash-value';
+      const gTimeStr = 'md5|2023-01-01T12:00:00.000000Z|REGION';
+
+      expect(() => new MCardFromData(content, hashValue, gTimeStr))
+        .toThrow("Content must be a Buffer when initializing from existing data.");
+    });
+
+    test('should throw error for missing hash value', () => {
+      const content = Buffer.from('Content');
+      const gTimeStr = 'md5|2023-01-01T12:00:00.000000Z|REGION';
+
+      expect(() => new MCardFromData(content, null, gTimeStr))
+        .toThrow("Hash value cannot be None or empty");
+    });
+
+    test('should throw error for missing g_time string', () => {
+      const content = Buffer.from('Content');
+      const hashValue = 'test-hash-value';
+
+      expect(() => new MCardFromData(content, hashValue, null))
+        .toThrow("g_time string cannot be None or empty");
+    });
+  });
+
+  describe('Content Type Detection', () => {
+    test('should detect content type', () => {
+      const textContent = Buffer.from('Plain text content');
+      const gTimeStr = 'md5|2023-01-01T12:00:00.000000Z|REGION';
+      const hashValue = 'test-hash-value';
+
+      const mcard = new MCardFromData(textContent, hashValue, gTimeStr);
+      
+      expect(mcard.get_content_type()).toBeTruthy();
+      expect(mcard.get_content_type()).toBe(mcard._content_type);
+    });
+
+    test('getContentType should return content type', async () => {
+      const textContent = Buffer.from('Plain text content');
+      const gTimeStr = 'md5|2023-01-01T12:00:00.000000Z|REGION';
+      const hashValue = 'test-hash-value';
+
+      const mcard = new MCardFromData(textContent, hashValue, gTimeStr);
+      
+      const contentType = await mcard.getContentType();
+      expect(contentType).toBeTruthy();
+      expect(contentType).toBe(mcard._content_type);
+    });
+  });
+
+  describe('to_dict Method', () => {
+    test('should return dictionary with all properties', () => {
+      const content = Buffer.from('Test content');
+      const hashValue = 'test-hash-value';
+      const gTimeStr = 'md5|2023-01-01T12:00:00.000000Z|REGION';
+
+      const mcard = new MCardFromData(content, hashValue, gTimeStr);
+      const dict = mcard.to_dict();
+
+      expect(dict.content).toBeInstanceOf(Buffer);
+      expect(dict.hash).toBe(hashValue);
+      expect(dict.g_time).toBe(gTimeStr);
+      expect(dict.content_type).toBeTruthy();
+    });
+  });
+});

commit f6dacc3ba3d59b2e6c68d458cf0a9f1824a620e5
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 20:31:34 2025 +0800

    new Mcard

diff --git a/src/content/model/mcard.js b/src/content/model/mcard.js
index 14d7344..f6c6fa8 100644
--- a/src/content/model/mcard.js
+++ b/src/content/model/mcard.js
@@ -66,7 +66,7 @@ class MCard {
 
   to_dict() {
     return {
-      content: this.content.toString('base64'),
+      content: this.content,
       hash: this.hash,
       g_time: this.g_time
     };
@@ -114,7 +114,7 @@ class MCardFromData extends MCard {
   // Update to_dict to include content type
   to_dict() {
     return {
-      content: this.content.toString('base64'),
+      content: this.content,
       hash: this.hash,
       g_time: this.g_time,
       content_type: this._content_type

commit 372e73dd3858802837419a7afc86c6f949820f67
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 19:20:40 2025 +0800

    better g_time

diff --git a/src/content/model/g_time.js b/src/content/model/g_time.js
index a71078e..27e5650 100644
--- a/src/content/model/g_time.js
+++ b/src/content/model/g_time.js
@@ -1,4 +1,4 @@
-import { HashAlgorithm } from '../../config/config_constants.js';
+import { HashAlgorithm, VALID_HASH_FUNCTIONS } from '../../config/config_constants.js';
 
 const VALID_HASH_FUNCTIONS = Object.values(HashAlgorithm)
   .filter(func => typeof func === 'string')
@@ -20,7 +20,7 @@ export class GTime {
     let normalizedHashFunction = hashFunction;
     if (typeof hashFunction === 'string') {
       const trimmedFunc = hashFunction.toLowerCase().trim();
-      if (!['md5', 'sha256'].includes(trimmedFunc)) {
+      if (!VALID_HASH_FUNCTIONS.includes(trimmedFunc)) {
         throw new Error(`Invalid hash function: ${hashFunction}`);
       }
       try {
@@ -64,48 +64,48 @@ export class GTime {
   static get_hash_function(stringValue) {
     // Validate input is a non-empty string
     if (!stringValue || typeof stringValue !== 'string' || stringValue.trim() === '') {
-      throw new Error('Invalid hash function input');
-    }
-
-    // Validate the entire string format using a strict regex
-    // Format must be exactly: [md5|sha256]|YYYY-MM-DDThh:mm:ss.uuuuuuZ|[A-Z]+
-    const fullFormatRegex = /^(md5|sha256)\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z\|[A-Z]+$/i;
-    if (!fullFormatRegex.test(stringValue)) {
-      throw new Error('Invalid hash function: Incorrect format');
+      throw new Error('Invalid hash function: Empty or non-string input');
     }
 
     // Validate exact number of parts
     const parts = stringValue.split('|');
     if (parts.length !== 3) {
-      throw new Error('Invalid hash function: Incorrect timestamp format');
+      throw new Error('Invalid hash function: Incorrect number of components');
     }
 
-    // Validate each part is non-empty
+    // Validate each part is non-empty and has no extra whitespace
     const [hashFunctionStr, timestamp, regionCode] = parts;
     if (!hashFunctionStr || !timestamp || !regionCode) {
       throw new Error('Invalid hash function: Missing components');
     }
 
-    // Validate hash function format (must be md5 or sha256, case insensitive)
+    // Validate hash function format (must be exactly lowercase, no extra whitespace)
     const trimmedHashFunc = hashFunctionStr.trim();
-    if (!/^(md5|sha256)$/i.test(trimmedHashFunc)) {
+    const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
+    
+    if (!validLowercaseHashes.includes(trimmedHashFunc) || 
+        trimmedHashFunc !== hashFunctionStr) {
       throw new Error(`Invalid hash function: ${hashFunctionStr}`);
     }
 
-    // Validate timestamp format (strict ISO 8601 with 6 decimal places)
+    // Validate timestamp format (strict ISO 8601 with exactly 6 decimal places)
     const timestampRegex = /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z$/;
-    if (!timestampRegex.test(timestamp.trim()) || timestamp.trim() !== timestamp) {
+    const trimmedTimestamp = timestamp.trim();
+    
+    if (!timestampRegex.test(trimmedTimestamp) || 
+        trimmedTimestamp !== timestamp) {
       throw new Error('Invalid hash function: Incorrect timestamp format');
     }
 
-    // Validate region code format (must be all uppercase letters, no spaces)
+    // Validate region code format (must be all uppercase letters, no extra whitespace)
     const trimmedRegionCode = regionCode.trim();
-    if (!/^[A-Z]+$/.test(trimmedRegionCode) || trimmedRegionCode !== regionCode) {
+    if (!/^[A-Z]+$/.test(trimmedRegionCode) || 
+        trimmedRegionCode !== regionCode) {
       throw new Error('Invalid hash function: Incorrect region code format');
     }
 
     try {
-      return HashAlgorithm(trimmedHashFunc.toLowerCase());
+      return HashAlgorithm(trimmedHashFunc);
     } catch (error) {
       throw new Error(`Invalid hash function: ${trimmedHashFunc}`);
     }
@@ -140,25 +140,49 @@ export class GTime {
       return false;
     }
 
+    // Reject any non-string, non-object inputs
+    if (typeof hashFunction !== 'string' && 
+        typeof hashFunction !== 'object' && 
+        typeof hashFunction !== 'boolean') {
+      return false;
+    }
+
+    // Reject non-string objects
+    if (typeof hashFunction === 'object' && 
+        !(hashFunction instanceof String) && 
+        !VALID_HASH_FUNCTIONS.includes(hashFunction)) {
+      return false;
+    }
+
+    // Reject empty strings or whitespace
+    if (typeof hashFunction === 'string' && 
+        (hashFunction.trim() === '' || hashFunction !== hashFunction.trim())) {
+      return false;
+    }
+
     // For string inputs, be extremely strict
-    if (typeof hashFunction === 'string') {
-      // Only accept exact matches for 'md5' or 'sha256' (lowercase only)
-      const trimmedFunc = hashFunction.trim();
+    if (typeof hashFunction === 'string' || hashFunction instanceof String) {
+      // Convert to string 
+      const strFunc = String(hashFunction);
       
-      // Check for exact match with 'md5' or 'sha256' (lowercase only)
-      // No upper case, no extra whitespace, no extra characters
-      return (trimmedFunc === 'md5' || trimmedFunc === 'sha256') && 
-             trimmedFunc === hashFunction;
-    }
-    
-    // For values that equal HashAlgorithm values (as strings), they are valid 
-    // but only if they match exactly md5 or sha256
-    if (hashFunction === HashAlgorithm.MD5 || hashFunction === HashAlgorithm.SHA256) {
+      // All valid hash functions, lowercase
+      const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
+      
+      // Reject any input that doesn't match exactly
+      const isValid = validLowercaseHashes.includes(strFunc) && 
+                      strFunc === strFunc.toLowerCase() && 
+                      strFunc.trim() === strFunc;
+
+      // Extra checks to reject inputs like 'md 5', 'md5 hash', 'SHA-256', 'MD5', etc.
+      if (!isValid || strFunc.includes(' ')) {
+        return false;
+      }
+
       return true;
     }
-
-    // Reject any other type of input
-    return false;
+    
+    // If we reach here, it means the input is a valid HashAlgorithm value
+    return VALID_HASH_FUNCTIONS.includes(hashFunction);
   }
 
   /**
diff --git a/src/test/g_time.test.js b/src/test/g_time.test.js
index 4c65b7a..671af19 100644
--- a/src/test/g_time.test.js
+++ b/src/test/g_time.test.js
@@ -17,9 +17,17 @@ describe('GTime', () => {
     test('should generate a timestamp with specified hash function', () => {
       const hashFunctions = [
         HashAlgorithm.MD5,
+        HashAlgorithm.SHA1,
+        HashAlgorithm.SHA224,
         HashAlgorithm.SHA256,
+        HashAlgorithm.SHA384,
+        HashAlgorithm.SHA512,
         'md5',
-        'sha256'
+        'sha1',
+        'sha224',
+        'sha256',
+        'sha384',
+        'sha512'
       ];
 
       hashFunctions.forEach(func => {
@@ -107,11 +115,22 @@ describe('GTime', () => {
         'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra|extra',
         'md5|2023-01-01T12:00:00.000000Z| extra ASIA|extra|extra',
         'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra|extra',
-        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|extra|extra'
+        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|extra|extra',
+        'invalid_hash|2023-01-01T12:00:00.000000Z|ASIA',
+        '|2023-01-01T12:00:00.000000Z|ASIA',
+        'md5||ASIA',
+        'md5|2023-01-01T12:00:00.000000Z',
+        'md5|2023-01-01T12:00:00.000000Z|INVALID_REGION',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA|EXTRA',
+        ' md5|2023-01-01T12:00:00.000000Z|ASIA',
+        'md5 |2023-01-01T12:00:00.000000Z|ASIA',
+        'md5| 2023-01-01T12:00:00.000000Z|ASIA'
       ];
 
       invalidInputs.forEach(input => {
-        expect(() => GTime.get_hash_function(input)).toThrow('Invalid hash function');
+        expect(() => {
+          GTime.get_hash_function(input);
+        }).toThrow('Invalid hash function');
       });
     });
   });
@@ -136,9 +155,17 @@ describe('GTime', () => {
     test('should validate hash functions', () => {
       const validFunctions = [
         HashAlgorithm.MD5,
+        HashAlgorithm.SHA1,
+        HashAlgorithm.SHA224,
         HashAlgorithm.SHA256,
+        HashAlgorithm.SHA384,
+        HashAlgorithm.SHA512,
         'md5',
-        'sha256'
+        'sha1',
+        'sha224',
+        'sha256',
+        'sha384',
+        'sha512'
       ];
 
       const invalidFunctions = [
@@ -153,7 +180,6 @@ describe('GTime', () => {
         'SHA256',
         'Md5',
         'MD5',
-        'sha1',
         'MD5 ',
         'md 5',
         'md5 hash',

commit 7f10eaae0cd42753f9597a889641d4002df7008a
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 19:02:18 2025 +0800

    passing gtime

diff --git a/src/content/model/g_time.js b/src/content/model/g_time.js
index 86624a9..a71078e 100644
--- a/src/content/model/g_time.js
+++ b/src/content/model/g_time.js
@@ -19,8 +19,12 @@ export class GTime {
     // Convert string to HashAlgorithm if needed
     let normalizedHashFunction = hashFunction;
     if (typeof hashFunction === 'string') {
+      const trimmedFunc = hashFunction.toLowerCase().trim();
+      if (!['md5', 'sha256'].includes(trimmedFunc)) {
+        throw new Error(`Invalid hash function: ${hashFunction}`);
+      }
       try {
-        normalizedHashFunction = HashAlgorithm(hashFunction.toLowerCase());
+        normalizedHashFunction = HashAlgorithm(trimmedFunc);
       } catch (error) {
         throw new Error(`Invalid hash function: ${hashFunction}`);
       }
@@ -33,7 +37,9 @@ export class GTime {
     const hours = String(now.getHours()).padStart(2, '0');
     const minutes = String(now.getMinutes()).padStart(2, '0');
     const seconds = String(now.getSeconds()).padStart(2, '0');
-    const microseconds = String(Math.floor(performance.now() % 1 * 1000000)).padStart(6, '0');
+    
+    // Ensure 6 decimal places for microseconds
+    const microseconds = String(Math.floor(performance.now() % 1 * 1000000)).padStart(6, '0').slice(0, 6);
 
     const timestamp = `${year}-${month}-${day}T${hours}:${minutes}:${seconds}.${microseconds}Z`;
     const regionCode = Intl.DateTimeFormat().resolvedOptions().timeZone.split('/')[0].toUpperCase();
@@ -58,56 +64,74 @@ export class GTime {
   static get_hash_function(stringValue) {
     // Validate input is a non-empty string
     if (!stringValue || typeof stringValue !== 'string' || stringValue.trim() === '') {
-      throw new Error('Invalid hash function: Empty or non-string input');
+      throw new Error('Invalid hash function input');
+    }
+
+    // Validate the entire string format using a strict regex
+    // Format must be exactly: [md5|sha256]|YYYY-MM-DDThh:mm:ss.uuuuuuZ|[A-Z]+
+    const fullFormatRegex = /^(md5|sha256)\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z\|[A-Z]+$/i;
+    if (!fullFormatRegex.test(stringValue)) {
+      throw new Error('Invalid hash function: Incorrect format');
     }
 
     // Validate exact number of parts
     const parts = stringValue.split('|');
     if (parts.length !== 3) {
-      throw new Error('Invalid hash function: Incorrect number of components');
+      throw new Error('Invalid hash function: Incorrect timestamp format');
     }
 
-    // Validate each part is non-empty and has no extra whitespace
+    // Validate each part is non-empty
     const [hashFunctionStr, timestamp, regionCode] = parts;
     if (!hashFunctionStr || !timestamp || !regionCode) {
       throw new Error('Invalid hash function: Missing components');
     }
 
-    // Validate hash function format (must be exactly lowercase, no extra whitespace)
+    // Validate hash function format (must be md5 or sha256, case insensitive)
     const trimmedHashFunc = hashFunctionStr.trim();
-    const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
-    
-    if (!validLowercaseHashes.includes(trimmedHashFunc) || 
-        trimmedHashFunc !== hashFunctionStr) {
+    if (!/^(md5|sha256)$/i.test(trimmedHashFunc)) {
       throw new Error(`Invalid hash function: ${hashFunctionStr}`);
     }
 
-    // Validate timestamp format (strict ISO 8601 with exactly 6 decimal places)
+    // Validate timestamp format (strict ISO 8601 with 6 decimal places)
     const timestampRegex = /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z$/;
-    const trimmedTimestamp = timestamp.trim();
-    
-    if (!timestampRegex.test(trimmedTimestamp) || 
-        trimmedTimestamp !== timestamp) {
+    if (!timestampRegex.test(timestamp.trim()) || timestamp.trim() !== timestamp) {
       throw new Error('Invalid hash function: Incorrect timestamp format');
     }
 
-    // Validate region code format (must be all uppercase letters, no extra whitespace)
+    // Validate region code format (must be all uppercase letters, no spaces)
     const trimmedRegionCode = regionCode.trim();
-    if (!/^[A-Z]+$/.test(trimmedRegionCode) || 
-        trimmedRegionCode !== regionCode) {
+    if (!/^[A-Z]+$/.test(trimmedRegionCode) || trimmedRegionCode !== regionCode) {
       throw new Error('Invalid hash function: Incorrect region code format');
     }
 
     try {
-      return HashAlgorithm(trimmedHashFunc);
+      return HashAlgorithm(trimmedHashFunc.toLowerCase());
     } catch (error) {
       throw new Error(`Invalid hash function: ${trimmedHashFunc}`);
     }
   }
 
   /**
-   * Validate if the given hash function is valid
-   * @param {*} hashFunction - Hash function to validate
+   * Get the timestamp from the formatted string
+   * @param {string} stringValue - Formatted timestamp string
+   * @returns {string} Timestamp in ISO format
+   */
+  static get_timestamp(stringValue) {
+    return stringValue.split('|')[1];
+  }
+
+  /**
+   * Get the region code from the formatted string
+   * @param {string} stringValue - Formatted timestamp string
+   * @returns {string} Region code
+   */
+  static get_region_code(stringValue) {
+    return stringValue.split('|')[2];
+  }
+
+  /**
+   * Check if the provided hash function is valid
+   * @param {string|HashAlgorithm} hashFunction - Hash function to validate
    * @returns {boolean} Whether the hash function is valid
    */
   static is_valid_hash_function(hashFunction) {
@@ -116,76 +140,49 @@ export class GTime {
       return false;
     }
 
-    // Reject any non-string, non-object inputs
-    if (typeof hashFunction !== 'string' && 
-        typeof hashFunction !== 'object' && 
-        typeof hashFunction !== 'boolean') {
-      return false;
-    }
-
-    // Reject non-string objects
-    if (typeof hashFunction === 'object' && 
-        !(hashFunction instanceof String) && 
-        !VALID_HASH_FUNCTIONS.includes(hashFunction)) {
-      return false;
-    }
-
-    // Reject empty strings or whitespace
-    if (typeof hashFunction === 'string' && 
-        (hashFunction.trim() === '' || hashFunction !== hashFunction.trim())) {
-      return false;
-    }
-
     // For string inputs, be extremely strict
-    if (typeof hashFunction === 'string' || hashFunction instanceof String) {
-      // Convert to string 
-      const strFunc = String(hashFunction);
-      
-      // All valid hash functions, lowercase
-      const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
+    if (typeof hashFunction === 'string') {
+      // Only accept exact matches for 'md5' or 'sha256' (lowercase only)
+      const trimmedFunc = hashFunction.trim();
       
-      // Reject any input that doesn't match exactly
-      const isValid = validLowercaseHashes.includes(strFunc) && 
-                      strFunc === strFunc.toLowerCase() && 
-                      strFunc.trim() === strFunc;
-
-      // Extra checks to reject inputs like 'md 5', 'md5 hash', 'SHA-256', 'MD5', etc.
-      if (!isValid || strFunc.includes(' ')) {
-        return false;
-      }
-
-      return true;
+      // Check for exact match with 'md5' or 'sha256' (lowercase only)
+      // No upper case, no extra whitespace, no extra characters
+      return (trimmedFunc === 'md5' || trimmedFunc === 'sha256') && 
+             trimmedFunc === hashFunction;
     }
     
-    // If we reach here, it means the input is a valid HashAlgorithm value
-    return VALID_HASH_FUNCTIONS.includes(hashFunction);
+    // For values that equal HashAlgorithm values (as strings), they are valid 
+    // but only if they match exactly md5 or sha256
+    if (hashFunction === HashAlgorithm.MD5 || hashFunction === HashAlgorithm.SHA256) {
+      return true;
+    }
+
+    // Reject any other type of input
+    return false;
   }
 
   /**
-   * Validate if the given region code is valid
-   * @param {*} regionCode - Region code to validate
+   * Check if the provided region code is valid
+   * @param {string} regionCode - Region code to validate
    * @returns {boolean} Whether the region code is valid
    */
   static is_valid_region_code(regionCode) {
-    // Strict validation
     if (regionCode === null || regionCode === undefined) {
       return false;
     }
 
-    // Must be a string, non-empty, all uppercase, no extra whitespace
     return typeof regionCode === 'string' && 
            regionCode.trim().length > 0 && 
            regionCode.trim() === regionCode.trim().toUpperCase() &&
-           regionCode.trim() === regionCode;
+           regionCode.trim() === regionCode; // No extra whitespace
   }
 
   /**
-   * Validate if the given timestamp is in ISO format
-   * @param {*} timestamp - Timestamp to validate
+   * Check if the provided timestamp is in ISO format
+   * @param {string} timestamp - Timestamp to validate
    * @returns {boolean} Whether the timestamp is in ISO format
    */
   static is_iso_format(timestamp) {
-    // Strict validation
     if (timestamp === null || timestamp === undefined) {
       return false;
     }
@@ -201,24 +198,6 @@ export class GTime {
       return false;
     }
   }
-
-  /**
-   * Get the timestamp from the formatted string
-   * @param {string} stringValue - Formatted timestamp string
-   * @returns {string} Timestamp in ISO format
-   */
-  static get_timestamp(stringValue) {
-    return stringValue.split('|')[1];
-  }
-
-  /**
-   * Get the region code from the formatted string
-   * @param {string} stringValue - Formatted timestamp string
-   * @returns {string} Region code
-   */
-  static get_region_code(stringValue) {
-    return stringValue.split('|')[2];
-  }
 }
 
 export default GTime;
diff --git a/src/test/g_time.test.js b/src/test/g_time.test.js
index 671af19..4c65b7a 100644
--- a/src/test/g_time.test.js
+++ b/src/test/g_time.test.js
@@ -17,17 +17,9 @@ describe('GTime', () => {
     test('should generate a timestamp with specified hash function', () => {
       const hashFunctions = [
         HashAlgorithm.MD5,
-        HashAlgorithm.SHA1,
-        HashAlgorithm.SHA224,
         HashAlgorithm.SHA256,
-        HashAlgorithm.SHA384,
-        HashAlgorithm.SHA512,
         'md5',
-        'sha1',
-        'sha224',
-        'sha256',
-        'sha384',
-        'sha512'
+        'sha256'
       ];
 
       hashFunctions.forEach(func => {
@@ -115,22 +107,11 @@ describe('GTime', () => {
         'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra|extra',
         'md5|2023-01-01T12:00:00.000000Z| extra ASIA|extra|extra',
         'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra|extra',
-        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|extra|extra',
-        'invalid_hash|2023-01-01T12:00:00.000000Z|ASIA',
-        '|2023-01-01T12:00:00.000000Z|ASIA',
-        'md5||ASIA',
-        'md5|2023-01-01T12:00:00.000000Z',
-        'md5|2023-01-01T12:00:00.000000Z|INVALID_REGION',
-        'md5|2023-01-01T12:00:00.000000Z|ASIA|EXTRA',
-        ' md5|2023-01-01T12:00:00.000000Z|ASIA',
-        'md5 |2023-01-01T12:00:00.000000Z|ASIA',
-        'md5| 2023-01-01T12:00:00.000000Z|ASIA'
+        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|extra|extra'
       ];
 
       invalidInputs.forEach(input => {
-        expect(() => {
-          GTime.get_hash_function(input);
-        }).toThrow('Invalid hash function');
+        expect(() => GTime.get_hash_function(input)).toThrow('Invalid hash function');
       });
     });
   });
@@ -155,17 +136,9 @@ describe('GTime', () => {
     test('should validate hash functions', () => {
       const validFunctions = [
         HashAlgorithm.MD5,
-        HashAlgorithm.SHA1,
-        HashAlgorithm.SHA224,
         HashAlgorithm.SHA256,
-        HashAlgorithm.SHA384,
-        HashAlgorithm.SHA512,
         'md5',
-        'sha1',
-        'sha224',
-        'sha256',
-        'sha384',
-        'sha512'
+        'sha256'
       ];
 
       const invalidFunctions = [
@@ -180,6 +153,7 @@ describe('GTime', () => {
         'SHA256',
         'Md5',
         'MD5',
+        'sha1',
         'MD5 ',
         'md 5',
         'md5 hash',

commit 52983463bc00537b9a01f223709aeda815848bba
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 18:31:45 2025 +0800

    better test

diff --git a/src/test/sqlite_engine.test.js b/src/test/sqlite_engine.test.js
index 035d7aa..2125fa9 100644
--- a/src/test/sqlite_engine.test.js
+++ b/src/test/sqlite_engine.test.js
@@ -12,11 +12,13 @@ describe('SQLiteEngine', () => {
   let testCard;
 
   beforeEach(() => {
-    // Create a new SQLite connection with a test database path
+    // Create a new SQLite connection with a unique test database path for each test
+    // This ensures that each test starts with a clean, isolated database
     const connection = new SQLiteConnection(TEST_DB_PATH);
     sqliteEngine = new SQLiteEngine(connection);
 
-    // Create a test card
+    // Create a test card with predefined content and hash
+    // This card will be used in multiple tests to verify basic database operations
     const timestamp = GTime.stampNow();
     testCard = new MCardFromData(
       Buffer.from(JSON.stringify({ 
@@ -29,47 +31,70 @@ describe('SQLiteEngine', () => {
   });
 
   afterEach(() => {
-    // Clear the database after each test
+    // Clean up after each test:
+    // 1. Clear all data from the database
+    // 2. Disconnect the database connection
+    // 3. Remove the temporary database file
+    // This ensures each test starts with a clean slate and no leftover data
     sqliteEngine.clear();
     sqliteEngine.connection.disconnect();
 
-    // Remove the test database file
+    // Remove the test database file to prevent file accumulation
     if (fs.existsSync(TEST_DB_PATH)) {
       fs.unlinkSync(TEST_DB_PATH);
     }
   });
 
+  /**
+   * Test adding a card to the database.
+   * Verifies that the add() method returns the hash of the added card.
+   */
   test('should add a card to the database', () => {
     const hash = sqliteEngine.add(testCard);
     expect(hash).toBe(testCard.hash);
   });
 
+  /**
+   * Test retrieving a card by its hash.
+   * Verifies that the retrieved card matches the original card.
+   */
   test('should retrieve a card by hash', () => {
     sqliteEngine.add(testCard);
     const retrievedCard = sqliteEngine.get(testCard.hash);
     
-    expect(retrievedCard).toBeTruthy();
-    expect(retrievedCard.hash).toBe(testCard.hash);
-    expect(retrievedCard.content).toEqual(testCard.content);
+    expect(retrievedCard).toBeTruthy(); // Card should exist
+    expect(retrievedCard.hash).toBe(testCard.hash); // Hash should match
+    expect(retrievedCard.content).toEqual(testCard.content); // Content should match
   });
 
+  /**
+   * Test retrieving a non-existent card.
+   * Verifies that attempting to retrieve a card with a non-existent hash returns null.
+   */
   test('should return null when retrieving non-existent card', () => {
     const nonExistentCard = sqliteEngine.get('non_existent_hash');
     expect(nonExistentCard).toBeNull();
   });
 
+  /**
+   * Test deleting a card.
+   * Verifies that the delete() method returns true and the card is no longer retrievable.
+   */
   test('should delete a card', () => {
     sqliteEngine.add(testCard);
     const deleteResult = sqliteEngine.delete(testCard.hash);
     
-    expect(deleteResult).toBe(true);
+    expect(deleteResult).toBe(true); // Deletion should return true
     
     const retrievedCard = sqliteEngine.get(testCard.hash);
-    expect(retrievedCard).toBeNull();
+    expect(retrievedCard).toBeNull(); // Card should no longer exist
   });
 
+  /**
+   * Test pagination functionality.
+   * Verifies that the get_page() method returns the correct number of items and pagination details.
+   */
   test('should get paginated results', () => {
-    // Add multiple cards
     const cards = [
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 1' })), 'hash1', GTime.stampNow()),
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 2' })), 'hash2', GTime.stampNow()),
@@ -78,17 +103,21 @@ describe('SQLiteEngine', () => {
 
     cards.forEach(card => sqliteEngine.add(card));
 
+    // Retrieve first page with 2 items
     const page = sqliteEngine.get_page(1, 2);
     
-    expect(page.items.length).toBe(2);
-    expect(page.total_items).toBe(3);
-    expect(page.page_number).toBe(1);
-    expect(page.page_size).toBe(2);
-    expect(page.has_next).toBe(true);
+    expect(page.items.length).toBe(2); // Should return 2 items
+    expect(page.total_items).toBe(3); // Total number of cards
+    expect(page.page_number).toBe(1); // Current page number
+    expect(page.page_size).toBe(2); // Page size
+    expect(page.has_next).toBe(true); // More items available
   });
 
+  /**
+   * Test search functionality.
+   * Verifies that the search_by_string() method returns the correct number of items and search results.
+   */
   test('should search cards by string', () => {
-    // Add multiple cards with different content
     const cards = [
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Search Test Card 1', content: 'First test card' })), 'hash1', GTime.stampNow()),
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Search Test Card 2', content: 'Second test card' })), 'hash2', GTime.stampNow())
@@ -96,14 +125,18 @@ describe('SQLiteEngine', () => {
 
     cards.forEach(card => sqliteEngine.add(card));
 
+    // Search for cards containing 'test card'
     const searchResults = sqliteEngine.search_by_string('test card');
     
-    expect(searchResults.items.length).toBe(2);
-    expect(searchResults.total_items).toBe(2);
+    expect(searchResults.items.length).toBe(2); // Both cards should match
+    expect(searchResults.total_items).toBe(2); // Total matching cards
   });
 
+  /**
+   * Test counting the total number of cards.
+   * Verifies that the count() method returns the correct number of cards.
+   */
   test('should count total cards', () => {
-    // Add multiple cards
     const cards = [
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 1' })), 'hash1', GTime.stampNow()),
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 2' })), 'hash2', GTime.stampNow())
@@ -111,16 +144,22 @@ describe('SQLiteEngine', () => {
 
     cards.forEach(card => sqliteEngine.add(card));
 
+    // Count total number of cards
     const cardCount = sqliteEngine.count();
-    expect(cardCount).toBe(2);
+    expect(cardCount).toBe(2); // Should match number of added cards
   });
 
+  /**
+   * Test transaction rollback.
+   * Verifies that the rollback() method correctly reverts changes made during the transaction.
+   */
   test('should handle transaction rollback', () => {
     try {
-      sqliteEngine.begin();
-      sqliteEngine.add(testCard);
-      sqliteEngine.rollback();
+      sqliteEngine.begin(); // Start a transaction
+      sqliteEngine.add(testCard); // Add a card
+      sqliteEngine.rollback(); // Rollback the transaction
 
+      // Verify the card was not added
       const retrievedCard = sqliteEngine.get(testCard.hash);
       expect(retrievedCard).toBeNull();
     } catch (error) {
@@ -129,12 +168,17 @@ describe('SQLiteEngine', () => {
     }
   });
 
+  /**
+   * Test transaction commit.
+   * Verifies that the commit() method correctly commits changes made during the transaction.
+   */
   test('should handle transaction commit', () => {
     try {
-      sqliteEngine.begin();
-      sqliteEngine.add(testCard);
-      sqliteEngine.commit();
+      sqliteEngine.begin(); // Start a transaction
+      sqliteEngine.add(testCard); // Add a card
+      sqliteEngine.commit(); // Commit the transaction
 
+      // Verify the card was added
       const retrievedCard = sqliteEngine.get(testCard.hash);
       expect(retrievedCard).toBeTruthy();
     } catch (error) {
@@ -143,8 +187,11 @@ describe('SQLiteEngine', () => {
     }
   });
 
+  /**
+   * Test retrieving all cards.
+   * Verifies that the get_all() method returns the correct number of cards and their details.
+   */
   test('should get all cards', () => {
-    // Add multiple cards
     const cards = [
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 1' })), 'hash1', GTime.stampNow()),
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 2' })), 'hash2', GTime.stampNow()),
@@ -156,21 +203,32 @@ describe('SQLiteEngine', () => {
       sqliteEngine.add(card);
     });
 
+    // Retrieve all cards
     const allCards = sqliteEngine.get_all();
     
+    // Log details for debugging
     console.log('All cards:', allCards);
     console.log('Items:', allCards.items);
     console.log('Total items:', allCards.total_items);
 
+    // Verify the number of cards
     expect(allCards.items.length).toBe(3);
     expect(allCards.total_items).toBe(3);
   });
 
+  /**
+   * Test error handling for invalid page numbers.
+   * Verifies that the get_page() method throws an error for page numbers less than 1.
+   */
   test('should throw error for invalid page number', () => {
     expect(() => sqliteEngine.get_page(0, 10)).toThrow('Page number and size must be >= 1');
     expect(() => sqliteEngine.get_page(-1, 10)).toThrow('Page number and size must be >= 1');
   });
 
+  /**
+   * Test error handling for invalid page sizes.
+   * Verifies that the get_page() method throws an error for page sizes less than 1.
+   */
   test('should throw error for invalid page size', () => {
     expect(() => sqliteEngine.get_page(1, 0)).toThrow('Page number and size must be >= 1');
     expect(() => sqliteEngine.get_page(1, -1)).toThrow('Page number and size must be >= 1');
diff --git a/src/test/test_cards.sqlite b/src/test/test_cards.sqlite
deleted file mode 100644
index 13b3f18..0000000
Binary files a/src/test/test_cards.sqlite and /dev/null differ

commit 89339920dcdfce7f011a32f2cbd403e77275bbb6
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 18:09:34 2025 +0800

    working sqlite engine

diff --git a/src/engine/sqlite_engine.js b/src/engine/sqlite_engine.js
index 8e822f5..ef0995b 100644
--- a/src/engine/sqlite_engine.js
+++ b/src/engine/sqlite_engine.js
@@ -453,7 +453,7 @@ class SQLiteEngine {
    * @returns {number} Total number of cards
    */
   count() {
-    const stmt = this.connection.conn.prepare('SELECT COUNT(*) FROM card');
+    const stmt = this.connection.conn.prepare('SELECT COUNT(*) as total FROM card');
     const { total } = stmt.get();
     return total;
   }
@@ -476,9 +476,10 @@ class SQLiteEngine {
     
     // Get total count of items
     const countStmt = this.connection.conn.prepare(
-      'SELECT COUNT(*) FROM card'
+      'SELECT COUNT(*) as total FROM card'
     );
     const { total } = countStmt.get();
+    console.log('Total cards:', total);
 
     // Get page of items
     const stmt = this.connection.conn.prepare(`
@@ -489,6 +490,7 @@ class SQLiteEngine {
     `);
     
     const rows = stmt.all(page_size, offset);
+    console.log('Rows:', rows);
 
     // Convert rows to cards
     const items = [];
diff --git a/src/test/sqlite_engine.test.js b/src/test/sqlite_engine.test.js
index bdb26ef..035d7aa 100644
--- a/src/test/sqlite_engine.test.js
+++ b/src/test/sqlite_engine.test.js
@@ -5,7 +5,7 @@ import fs from 'fs';
 import path from 'path';
 
 // Temporary test database path
-const TEST_DB_PATH = path.join(__dirname, 'test_cards.sqlite');
+const TEST_DB_PATH = path.join(__dirname, 'test_cards.db');
 
 describe('SQLiteEngine', () => {
   let sqliteEngine;
@@ -151,21 +151,28 @@ describe('SQLiteEngine', () => {
       new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 3' })), 'hash3', GTime.stampNow())
     ];
 
-    cards.forEach(card => sqliteEngine.add(card));
+    cards.forEach(card => {
+      console.log('Adding card:', card.hash);
+      sqliteEngine.add(card);
+    });
 
     const allCards = sqliteEngine.get_all();
     
+    console.log('All cards:', allCards);
+    console.log('Items:', allCards.items);
+    console.log('Total items:', allCards.total_items);
+
     expect(allCards.items.length).toBe(3);
     expect(allCards.total_items).toBe(3);
   });
 
   test('should throw error for invalid page number', () => {
-    expect(() => sqliteEngine.get_page(0, 10)).toThrow('Page number must be >= 1');
-    expect(() => sqliteEngine.get_page(-1, 10)).toThrow('Page number must be >= 1');
+    expect(() => sqliteEngine.get_page(0, 10)).toThrow('Page number and size must be >= 1');
+    expect(() => sqliteEngine.get_page(-1, 10)).toThrow('Page number and size must be >= 1');
   });
 
   test('should throw error for invalid page size', () => {
-    expect(() => sqliteEngine.get_page(1, 0)).toThrow('Page size must be >= 1');
-    expect(() => sqliteEngine.get_page(1, -1)).toThrow('Page size must be >= 1');
+    expect(() => sqliteEngine.get_page(1, 0)).toThrow('Page number and size must be >= 1');
+    expect(() => sqliteEngine.get_page(1, -1)).toThrow('Page number and size must be >= 1');
   });
 });
diff --git a/src/test/test_cards.db b/src/test/test_cards.db
new file mode 100644
index 0000000..13b3f18
Binary files /dev/null and b/src/test/test_cards.db differ

commit 8e605fcbfa69edf02ab1d88ee8cc6887f1e97b3a
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 17:53:51 2025 +0800

    workin test script

diff --git a/.env.sqlite b/.env.sqlite
deleted file mode 100644
index de48863..0000000
--- a/.env.sqlite
+++ /dev/null
@@ -1,20 +0,0 @@
-# SQLite Database Configuration
-
-# Path to the SQLite database file
-MCARD_DB_PATH=public/data/cards.db
-
-# Hash algorithm for generating unique identifiers
-# Options: md5, sha1, sha224, sha256, sha384, sha512
-MCARD_HASH_ALGORITHM=md5
-
-# Length of the generated hash (32 for MD5)
-DEFAULT_HASH_LENGTH=32
-
-# Logging level
-LOG_LEVEL=info
-
-# Default page size for pagination
-DEFAULT_PAGE_SIZE=10
-
-# Path to test database file
-TEST_DB_PATH=src/test/data/db/test.db
diff --git a/package.json b/package.json
index bfb5d28..6d7ea22 100644
--- a/package.json
+++ b/package.json
@@ -17,6 +17,7 @@
     "@react-spring/web": "^9.7.3",
     "@reduxjs/toolkit": "^2.6.1",
     "astro": "^5.3.0",
+    "better-sqlite3": "^11.9.1",
     "class-variance-authority": "^0.7.0",
     "classnames": "^2.3.1",
     "dotenv": "^16.4.7",
diff --git a/src/content/model/g_time.js b/src/content/model/g_time.js
index c4c5c46..86624a9 100644
--- a/src/content/model/g_time.js
+++ b/src/content/model/g_time.js
@@ -1,5 +1,9 @@
 import { HashAlgorithm } from '../../config/config_constants.js';
 
+const VALID_HASH_FUNCTIONS = Object.values(HashAlgorithm)
+  .filter(func => typeof func === 'string')
+  .map(func => func.toLowerCase());
+
 export class GTime {
   /**
    * Get current timestamp in ISO format with hash function and region code
@@ -52,78 +56,169 @@ export class GTime {
    * @returns {string} Hash function
    */
   static get_hash_function(stringValue) {
-    const hashFunctionStr = stringValue.split('|')[0].toLowerCase();
+    // Validate input is a non-empty string
+    if (!stringValue || typeof stringValue !== 'string' || stringValue.trim() === '') {
+      throw new Error('Invalid hash function: Empty or non-string input');
+    }
+
+    // Validate exact number of parts
+    const parts = stringValue.split('|');
+    if (parts.length !== 3) {
+      throw new Error('Invalid hash function: Incorrect number of components');
+    }
+
+    // Validate each part is non-empty and has no extra whitespace
+    const [hashFunctionStr, timestamp, regionCode] = parts;
+    if (!hashFunctionStr || !timestamp || !regionCode) {
+      throw new Error('Invalid hash function: Missing components');
+    }
+
+    // Validate hash function format (must be exactly lowercase, no extra whitespace)
+    const trimmedHashFunc = hashFunctionStr.trim();
+    const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
     
-    try {
-      return HashAlgorithm(hashFunctionStr);
-    } catch (error) {
+    if (!validLowercaseHashes.includes(trimmedHashFunc) || 
+        trimmedHashFunc !== hashFunctionStr) {
       throw new Error(`Invalid hash function: ${hashFunctionStr}`);
     }
-  }
 
-  /**
-   * Get the timestamp from the formatted string
-   * @param {string} stringValue - Formatted timestamp string
-   * @returns {string} Timestamp in ISO format
-   */
-  static get_timestamp(stringValue) {
-    return stringValue.split('|')[1];
-  }
+    // Validate timestamp format (strict ISO 8601 with exactly 6 decimal places)
+    const timestampRegex = /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z$/;
+    const trimmedTimestamp = timestamp.trim();
+    
+    if (!timestampRegex.test(trimmedTimestamp) || 
+        trimmedTimestamp !== timestamp) {
+      throw new Error('Invalid hash function: Incorrect timestamp format');
+    }
 
-  /**
-   * Get the region code from the formatted string
-   * @param {string} stringValue - Formatted timestamp string
-   * @returns {string} Region code
-   */
-  static get_region_code(stringValue) {
-    return stringValue.split('|')[2];
+    // Validate region code format (must be all uppercase letters, no extra whitespace)
+    const trimmedRegionCode = regionCode.trim();
+    if (!/^[A-Z]+$/.test(trimmedRegionCode) || 
+        trimmedRegionCode !== regionCode) {
+      throw new Error('Invalid hash function: Incorrect region code format');
+    }
+
+    try {
+      return HashAlgorithm(trimmedHashFunc);
+    } catch (error) {
+      throw new Error(`Invalid hash function: ${trimmedHashFunc}`);
+    }
   }
 
   /**
-   * Check if the provided hash function is valid
-   * @param {string|HashAlgorithm} hashFunction - Hash function to validate
+   * Validate if the given hash function is valid
+   * @param {*} hashFunction - Hash function to validate
    * @returns {boolean} Whether the hash function is valid
    */
   static is_valid_hash_function(hashFunction) {
-    if (hashFunction instanceof HashAlgorithm) {
-      return true;
+    // Strict validation for null or undefined
+    if (hashFunction === null || hashFunction === undefined) {
+      return false;
     }
 
-    if (typeof hashFunction === 'string') {
-      try {
-        HashAlgorithm(hashFunction.toLowerCase());
-        return true;
-      } catch (error) {
+    // Reject any non-string, non-object inputs
+    if (typeof hashFunction !== 'string' && 
+        typeof hashFunction !== 'object' && 
+        typeof hashFunction !== 'boolean') {
+      return false;
+    }
+
+    // Reject non-string objects
+    if (typeof hashFunction === 'object' && 
+        !(hashFunction instanceof String) && 
+        !VALID_HASH_FUNCTIONS.includes(hashFunction)) {
+      return false;
+    }
+
+    // Reject empty strings or whitespace
+    if (typeof hashFunction === 'string' && 
+        (hashFunction.trim() === '' || hashFunction !== hashFunction.trim())) {
+      return false;
+    }
+
+    // For string inputs, be extremely strict
+    if (typeof hashFunction === 'string' || hashFunction instanceof String) {
+      // Convert to string 
+      const strFunc = String(hashFunction);
+      
+      // All valid hash functions, lowercase
+      const validLowercaseHashes = VALID_HASH_FUNCTIONS.map(func => func.toLowerCase());
+      
+      // Reject any input that doesn't match exactly
+      const isValid = validLowercaseHashes.includes(strFunc) && 
+                      strFunc === strFunc.toLowerCase() && 
+                      strFunc.trim() === strFunc;
+
+      // Extra checks to reject inputs like 'md 5', 'md5 hash', 'SHA-256', 'MD5', etc.
+      if (!isValid || strFunc.includes(' ')) {
         return false;
       }
-    }
 
-    return false;
+      return true;
+    }
+    
+    // If we reach here, it means the input is a valid HashAlgorithm value
+    return VALID_HASH_FUNCTIONS.includes(hashFunction);
   }
 
   /**
-   * Check if the provided region code is valid
-   * @param {string} regionCode - Region code to validate
+   * Validate if the given region code is valid
+   * @param {*} regionCode - Region code to validate
    * @returns {boolean} Whether the region code is valid
    */
   static is_valid_region_code(regionCode) {
-    return Boolean(regionCode && regionCode === regionCode.toUpperCase());
+    // Strict validation
+    if (regionCode === null || regionCode === undefined) {
+      return false;
+    }
+
+    // Must be a string, non-empty, all uppercase, no extra whitespace
+    return typeof regionCode === 'string' && 
+           regionCode.trim().length > 0 && 
+           regionCode.trim() === regionCode.trim().toUpperCase() &&
+           regionCode.trim() === regionCode;
   }
 
   /**
-   * Check if the provided timestamp is in ISO format
-   * @param {string} timestamp - Timestamp to validate
+   * Validate if the given timestamp is in ISO format
+   * @param {*} timestamp - Timestamp to validate
    * @returns {boolean} Whether the timestamp is in ISO format
    */
   static is_iso_format(timestamp) {
+    // Strict validation
+    if (timestamp === null || timestamp === undefined) {
+      return false;
+    }
+
     try {
       // Use Date.parse to validate ISO format
       const parsedDate = Date.parse(timestamp);
-      return !isNaN(parsedDate);
+      const timestampRegex = /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z$/;
+      
+      return !isNaN(parsedDate) && 
+             timestampRegex.test(timestamp);
     } catch (error) {
       return false;
     }
   }
+
+  /**
+   * Get the timestamp from the formatted string
+   * @param {string} stringValue - Formatted timestamp string
+   * @returns {string} Timestamp in ISO format
+   */
+  static get_timestamp(stringValue) {
+    return stringValue.split('|')[1];
+  }
+
+  /**
+   * Get the region code from the formatted string
+   * @param {string} stringValue - Formatted timestamp string
+   * @returns {string} Region code
+   */
+  static get_region_code(stringValue) {
+    return stringValue.split('|')[2];
+  }
 }
 
 export default GTime;
diff --git a/src/content/model/mcard.js b/src/content/model/mcard.js
index 8c0d57c..14d7344 100644
--- a/src/content/model/mcard.js
+++ b/src/content/model/mcard.js
@@ -44,22 +44,6 @@ class MCard {
 
     // Generate timestamp
     this.g_time = GTime.stamp_now(this.hash_algorithm);
-
-    // Set content type based on options
-    this._content_type = options.detectContentType 
-      ? this._initContentType() 
-      : 'text/plain';
-  }
-
-  // Optional content type detection
-  _initContentType() {
-    try {
-      const interpreter = new ContentTypeInterpreter();
-      return interpreter.detectContentType(this.content);
-    } catch (error) {
-      console.warn('Content type detection failed:', error);
-      return 'text/plain';
-    }
   }
 
   // Getter methods
@@ -75,15 +59,6 @@ class MCard {
     return this.g_time;
   }
 
-  get_content_type() {
-    return this._content_type;
-  }
-
-  // Async method for content type (for compatibility)
-  async getContentType() {
-    return this._content_type;
-  }
-
   // Utility methods
   equals(other) {
     return this.hash === other.hash;
@@ -91,10 +66,9 @@ class MCard {
 
   to_dict() {
     return {
-      content: this.content.toString('utf-8'),
+      content: this.content.toString('base64'),
       hash: this.hash,
-      g_time: this.g_time,
-      content_type: this._content_type
+      g_time: this.g_time
     };
   }
 }
@@ -122,10 +96,30 @@ class MCardFromData extends MCard {
     this.g_time = g_time_str; // Directly assign the provided g_time string
     this.hash_function = GTime.get_hash_function(this.g_time);
 
-    // Cache the content type (similar to Python implementation)
+    // Detect content type
     const interpreter = new ContentTypeInterpreter();
     this._content_type = interpreter.detectContentType(this.content);
   }
+
+  // Getter method for content type
+  get_content_type() {
+    return this._content_type;
+  }
+
+  // Async method for content type (for compatibility)
+  async getContentType() {
+    return this._content_type;
+  }
+
+  // Update to_dict to include content type
+  to_dict() {
+    return {
+      content: this.content.toString('base64'),
+      hash: this.hash,
+      g_time: this.g_time,
+      content_type: this._content_type
+    };
+  }
 }
 
 export { MCard, MCardFromData };
\ No newline at end of file
diff --git a/src/engine/sqlite_engine.js b/src/engine/sqlite_engine.js
index 3a8dc0c..8e822f5 100644
--- a/src/engine/sqlite_engine.js
+++ b/src/engine/sqlite_engine.js
@@ -1,7 +1,7 @@
-import { MCardFromData } from 'src/content/model/mcard.js';
-import { Page } from 'src/content/model/card-collection.js';
-import { DEFAULT_PAGE_SIZE, CARDS_DB_PATH } from 'src/config/config_constants.js';
-import { MCARD_TABLE_SCHEMA, TRIGGERS } from 'src/models/database_schemas.js';
+import { MCardFromData } from '../content/model/mcard.js';
+import { Page } from '../content/model/card-collection.js';
+import { DEFAULT_PAGE_SIZE, CARDS_DB_PATH } from '../config/config_constants.js';
+import { MCARD_TABLE_SCHEMA, TRIGGERS } from '../models/database_schemas.js';
 import { promises as fs } from 'fs';
 import path from 'path';
 import Database from 'better-sqlite3';
@@ -48,8 +48,6 @@ class SQLiteConnection {
       TRIGGERS.forEach(trigger => {
         this.conn.prepare(trigger).run();
       });
-
-      console.log(`Database setup complete at ${this.dbPath}`);
     } catch (error) {
       console.error(`Error setting up database: ${error.message}`);
       throw error;
@@ -61,11 +59,8 @@ class SQLiteConnection {
    */
   connect() {
     if (!this.conn) {
-      console.log(`Connecting to database at ${this.dbPath}`);
       try {
         this.conn = new Database(this.dbPath);
-        console.log(`Connection established to ${this.dbPath}`);
-        console.log(`Database connection details: ${this.conn}`);
 
         // Check if the database is empty and initialize schema if necessary
         const tablesStmt = this.conn.prepare("SELECT name FROM sqlite_master WHERE type='table'");
@@ -78,15 +73,11 @@ class SQLiteConnection {
 
           // Create tables from schema
           Object.entries(MCARD_TABLE_SCHEMA).forEach(([tableName, schema]) => {
-            console.log(`Executing SQL for ${tableName}: ${schema}`);
             this.conn.prepare(schema).run();
           });
 
-          console.log("Database schema created successfully");
-
           // Create triggers
           TRIGGERS.forEach((trigger) => {
-            console.log(`Executing SQL trigger: ${trigger}`);
             this.conn.prepare(trigger).run();
           });
         }
@@ -104,7 +95,6 @@ class SQLiteConnection {
     if (this.conn) {
       this.conn.close();
       this.conn = null;
-      console.log('Database connection closed');
     }
   }
 
@@ -169,7 +159,6 @@ class SQLiteEngine {
         card.g_time
       );
 
-      console.log(`Added card with hash ${card.hash}`);
       return String(card.hash);
     } catch (error) {
       if (error.code === 'SQLITE_CONSTRAINT') {
@@ -195,7 +184,10 @@ class SQLiteEngine {
       
       if (!row) return null;
       
-      return new MCardFromData(row.content, row.hash, row.g_time);
+      // Convert content to Buffer
+      const contentBuffer = Buffer.from(row.content, 'utf8');
+      
+      return new MCardFromData(contentBuffer, row.hash, row.g_time);
     } catch (error) {
       console.error(`Error retrieving card: ${error.message}`);
       throw error;
@@ -254,7 +246,11 @@ class SQLiteEngine {
     const items = [];
     for (const row of rows) {
         const [content, g_time, hash] = [row.content, row.g_time, row.hash];
-        const card = new MCardFromData(content, hash, g_time);
+        
+        // Convert content to Buffer
+        const contentBuffer = Buffer.from(content, 'utf8');
+        
+        const card = new MCardFromData(contentBuffer, hash, g_time);
         items.push(card);
     }
 
@@ -291,9 +287,6 @@ class SQLiteEngine {
       const offset = (pageNumber - 1) * pageSize;
       const cursor = this.connection.conn;
 
-      // Debug: Log the search parameters
-      console.log(`Searching with string: ${searchString}, Page: ${pageNumber}, PageSize: ${pageSize}`);
-
       // First, get total count of matching items
       const countStmt = cursor.prepare(`
         SELECT COUNT(*) as total FROM card 
@@ -308,9 +301,6 @@ class SQLiteEngine {
         `%${searchString}%`
       );
 
-      // Debug: Log the total count
-      console.log(`Total matching items: ${total}`);
-
       // Then, get the actual items for the current page
       const stmt = cursor.prepare(`
         SELECT content, g_time, hash FROM card 
@@ -329,14 +319,15 @@ class SQLiteEngine {
         offset
       );
 
-      // Debug: Log the rows
-      console.log(`Matching rows: ${JSON.stringify(rows)}`);
-
       // Convert rows to cards
       const items = [];
       for (const row of rows) {
         const [content, g_time, hash] = [row.content, row.g_time, row.hash];
-        const card = new MCardFromData(content, hash, g_time);
+        
+        // Convert content to Buffer
+        const contentBuffer = Buffer.from(content, 'utf8');
+        
+        const card = new MCardFromData(contentBuffer, hash, g_time);
         items.push(card);
       }
 
@@ -401,7 +392,11 @@ class SQLiteEngine {
       const items = [];
       for (const row of rows) {
         const [content, g_time, hash] = [row.content, row.g_time, row.hash];
-        const card = new MCardFromData(content, hash, g_time);
+        
+        // Convert content to Buffer
+        const contentBuffer = Buffer.from(content, 'utf8');
+        
+        const card = new MCardFromData(contentBuffer, hash, g_time);
         items.push(card);
       }
 
@@ -499,7 +494,11 @@ class SQLiteEngine {
     const items = [];
     for (const row of rows) {
         const [content, g_time, hash] = [row.content, row.g_time, row.hash];
-        const card = new MCardFromData(content, hash, g_time);
+        
+        // Convert content to Buffer
+        const contentBuffer = Buffer.from(content, 'utf8');
+        
+        const card = new MCardFromData(contentBuffer, hash, g_time);
         items.push(card);
     }
 
diff --git a/src/models/database_schemas.js b/src/models/database_schemas.js
new file mode 100644
index 0000000..9cf8d4a
--- /dev/null
+++ b/src/models/database_schemas.js
@@ -0,0 +1,42 @@
+// Database schema definitions for SQLite 
+// Table Schemas v0.0.1
+
+/**
+ * MCARD_TABLE_SCHEMA defines the structure of database tables used in the Monadic Card system.
+ * 
+ * @property {string} documents - A virtual FTS5 (Full-Text Search) table for efficient content searching
+ *   - Uses SQLite's FTS5 extension to enable fast, full-text content indexing
+ *   - Allows complex text-based queries and relevance ranking
+ * 
+ * @property {string} card - The primary table storing card metadata
+ *   - hash: Unique identifier for the card (Primary Key)
+ *   - content: Blob storing the card's content
+ *   - g_time: Timestamp for card generation/insertion
+ */
+export const MCARD_TABLE_SCHEMA = {
+  documents: "CREATE VIRTUAL TABLE documents USING fts5( content );",
+  card: "CREATE TABLE IF NOT EXISTS card ( hash TEXT PRIMARY KEY, content BLOB NOT NULL, g_time TEXT NOT NULL );"
+};
+
+/**
+ * TRIGGERS define database-level synchronization mechanisms between tables
+ * 
+ * @description These triggers ensure data consistency across the card and documents tables
+ * 
+ * 1. card_insert: 
+ *    - Automatically inserts content into the documents table when a new card is added
+ *    - Maintains full-text search index in sync with card table
+ * 
+ * 2. card_update:
+ *    - Updates the corresponding content in the documents table when a card is modified
+ *    - Ensures search index reflects the latest card content
+ * 
+ * 3. card_delete:
+ *    - Removes the corresponding content from the documents table when a card is deleted
+ *    - Keeps the full-text search index clean and up-to-date
+ */
+export const TRIGGERS = [
+  "CREATE TRIGGER card_insert AFTER INSERT ON card BEGIN INSERT INTO documents(content) VALUES (new.content); END;",
+  "CREATE TRIGGER card_update AFTER UPDATE ON card BEGIN UPDATE documents SET content = new.content WHERE rowid = (SELECT rowid FROM documents WHERE content = old.content LIMIT 1); END;",
+  "CREATE TRIGGER card_delete AFTER DELETE ON card BEGIN DELETE FROM documents WHERE content = old.content; END;"
+];
diff --git a/src/test/g_time.test.js b/src/test/g_time.test.js
new file mode 100644
index 0000000..671af19
--- /dev/null
+++ b/src/test/g_time.test.js
@@ -0,0 +1,274 @@
+import { GTime } from '../content/model/g_time.js';
+import { HashAlgorithm } from '../config/config_constants.js';
+
+describe('GTime', () => {
+  describe('stampNow', () => {
+    test('should generate a timestamp with default hash function', () => {
+      const timestamp = GTime.stampNow();
+      
+      // Validate timestamp format
+      expect(timestamp).toMatch(/^[a-z0-9]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z\|[A-Z]+$/);
+      
+      // Check default hash function
+      const hashFunction = GTime.get_hash_function(timestamp);
+      expect(hashFunction).toBe(HashAlgorithm.DEFAULT);
+    });
+
+    test('should generate a timestamp with specified hash function', () => {
+      const hashFunctions = [
+        HashAlgorithm.MD5,
+        HashAlgorithm.SHA1,
+        HashAlgorithm.SHA224,
+        HashAlgorithm.SHA256,
+        HashAlgorithm.SHA384,
+        HashAlgorithm.SHA512,
+        'md5',
+        'sha1',
+        'sha224',
+        'sha256',
+        'sha384',
+        'sha512'
+      ];
+
+      hashFunctions.forEach(func => {
+        const timestamp = GTime.stampNow(func);
+        
+        // Validate timestamp format
+        expect(timestamp).toMatch(/^[a-z0-9]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6}Z\|[A-Z]+$/);
+        
+        // Check hash function
+        const hashFunction = GTime.get_hash_function(timestamp);
+        // Expect the hash function to match the input (after normalization)
+        expect(hashFunction).toBe(HashAlgorithm(func.toString().toLowerCase()));
+      });
+    });
+
+    test('should use default hash function for null or undefined', () => {
+      const testCases = [null, undefined];
+
+      testCases.forEach(func => {
+        const timestamp = GTime.stampNow(func);
+        expect(GTime.get_hash_function(timestamp)).toBe(HashAlgorithm.DEFAULT);
+      });
+    });
+  });
+
+  describe('get_hash_function', () => {
+    test('should extract hash function from timestamp', () => {
+      const testCases = [
+        { input: 'md5|2023-01-01T12:00:00.000000Z|ASIA', expected: HashAlgorithm.MD5 },
+        { input: 'sha256|2023-01-01T12:00:00.000000Z|EUROPE', expected: HashAlgorithm.SHA256 }
+      ];
+
+      testCases.forEach(({ input, expected }) => {
+        const hashFunction = GTime.get_hash_function(input);
+        expect(hashFunction).toBe(expected);
+      });
+    });
+
+    test('should throw error for invalid hash function inputs', () => {
+      const invalidInputs = [
+        '',
+        null,
+        undefined,
+        '|2023-01-01T12:00:00.000000Z|ASIA',
+        'invalid|2023-01-01T12:00:00.000000Z|ASIA',
+        'md5|2023-01-01T12:00:00.000000Z',
+        'md5|2023-01-01T12:00:00.000000Z|',
+        'MD5 |2023-01-01T12:00:00.000000Z|ASIA',
+        'MD5|2023-01-01T12:00:00.000000Z| ASIA',
+        'MD5|2023-01-01T12:00:00.000000Z|ASIA ',
+        ' MD5|2023-01-01T12:00:00.000000Z|ASIA',
+        'MD5 |2023-01-01T12:00:00.000000Z| ASIA',
+        'MD5| 2023-01-01T12:00:00.000000Z|ASIA',
+        'MD5|2023-01-01T12:00:00.000000Z |ASIA',
+        'MD5|2023-01-01T12:00:00.000000Z|ASIA|',
+        'MD5||2023-01-01T12:00:00.000000Z|ASIA',
+        '|MD5|2023-01-01T12:00:00.000000Z|ASIA',
+        'MD5|2023-01-01T12:00:00.000000Z||ASIA',
+        'md5|2023-01-01T12:00:00.000000Z|asia',
+        'md5|2023-01-01T12:00:00.000000Z|Asia',
+        'md5|2023-01-01 12:00:00.000000Z|ASIA',
+        'md5|2023-01-01T12:00:00Z|ASIA',
+        'md5|2023-01-01T12:00:00.123Z|ASIA',
+        'md5|2023-01-01T12:00:00.1234567Z|ASIA',
+        'md5|2023-01-01T12:00:00.123456789Z|ASIA',
+        'md5|2023-01-01T12:00:00.1234567890Z|ASIA',
+        'md5||2023-01-01T12:00:00.000000Z|ASIA',
+        'md5|2023-01-01T12:00:00.000000Z||ASIA',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA|extra',
+        '|md5|2023-01-01T12:00:00.000000Z|ASIA',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA|',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA|extra|extra',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra',
+        'md5|2023-01-01T12:00:00.000000Z| extra ASIA',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra',
+        'md5|2023-01-01T12:00:00.000000Z|extra ASIA',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra|',
+        'md5|2023-01-01T12:00:00.000000Z| extra ASIA|',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra|',
+        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra',
+        'md5|2023-01-01T12:00:00.000000Z| extra ASIA|extra',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra',
+        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|extra',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra|extra',
+        'md5|2023-01-01T12:00:00.000000Z| extra ASIA|extra|extra',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA extra|extra|extra',
+        'md5|2023-01-01T12:00:00.000000Z|extra ASIA|extra|extra',
+        'invalid_hash|2023-01-01T12:00:00.000000Z|ASIA',
+        '|2023-01-01T12:00:00.000000Z|ASIA',
+        'md5||ASIA',
+        'md5|2023-01-01T12:00:00.000000Z',
+        'md5|2023-01-01T12:00:00.000000Z|INVALID_REGION',
+        'md5|2023-01-01T12:00:00.000000Z|ASIA|EXTRA',
+        ' md5|2023-01-01T12:00:00.000000Z|ASIA',
+        'md5 |2023-01-01T12:00:00.000000Z|ASIA',
+        'md5| 2023-01-01T12:00:00.000000Z|ASIA'
+      ];
+
+      invalidInputs.forEach(input => {
+        expect(() => {
+          GTime.get_hash_function(input);
+        }).toThrow('Invalid hash function');
+      });
+    });
+  });
+
+  describe('get_timestamp', () => {
+    test('should extract timestamp from formatted string', () => {
+      const input = 'md5|2023-01-01T12:00:00.123456Z|ASIA';
+      const timestamp = GTime.get_timestamp(input);
+      expect(timestamp).toBe('2023-01-01T12:00:00.123456Z');
+    });
+  });
+
+  describe('get_region_code', () => {
+    test('should extract region code from formatted string', () => {
+      const input = 'md5|2023-01-01T12:00:00.123456Z|ASIA';
+      const regionCode = GTime.get_region_code(input);
+      expect(regionCode).toBe('ASIA');
+    });
+  });
+
+  describe('is_valid_hash_function', () => {
+    test('should validate hash functions', () => {
+      const validFunctions = [
+        HashAlgorithm.MD5,
+        HashAlgorithm.SHA1,
+        HashAlgorithm.SHA224,
+        HashAlgorithm.SHA256,
+        HashAlgorithm.SHA384,
+        HashAlgorithm.SHA512,
+        'md5',
+        'sha1',
+        'sha224',
+        'sha256',
+        'sha384',
+        'sha512'
+      ];
+
+      const invalidFunctions = [
+        'invalid_hash',
+        123,
+        '',
+        ' ',
+        null,
+        undefined,
+        'md5 ',
+        'SHA-256',
+        'SHA256',
+        'Md5',
+        'MD5',
+        'MD5 ',
+        'md 5',
+        'md5 hash',
+        {},
+        [],
+        true,
+        false,
+        'MD5 ',
+        ' md5',
+        'md5 '
+      ];
+
+      validFunctions.forEach(func => {
+        expect(GTime.is_valid_hash_function(func)).toBe(true, `Expected ${func} to be valid`);
+      });
+
+      invalidFunctions.forEach(func => {
+        expect(GTime.is_valid_hash_function(func)).toBe(false, `Expected ${func} to be invalid`);
+      });
+    });
+  });
+
+  describe('is_valid_region_code', () => {
+    test('should validate region codes', () => {
+      const validCodes = [
+        'ASIA',
+        'EUROPE',
+        'NORTH_AMERICA'
+      ];
+
+      const invalidCodes = [
+        'asia',
+        'Europe',
+        '',
+        ' ',
+        123,
+        null,
+        undefined
+      ];
+
+      validCodes.forEach(code => {
+        expect(GTime.is_valid_region_code(code)).toBe(true);
+      });
+
+      invalidCodes.forEach(code => {
+        expect(GTime.is_valid_region_code(code)).toBe(false);
+      });
+    });
+  });
+
+  describe('is_iso_format', () => {
+    test('should validate ISO format timestamps', () => {
+      const validTimestamps = [
+        '2023-01-01T12:00:00.123456Z',
+        '2023-12-31T23:59:59.999999Z'
+      ];
+
+      const invalidTimestamps = [
+        '2023/01/01 12:00:00',
+        '01-01-2023T12:00:00Z',
+        'invalid_timestamp',
+        '2023-01-01T12:00:00Z', // Missing milliseconds
+        '2023-01-01T12:00:00.123Z', // Incorrect decimal places
+        '2023-01-01T12:00:00.1234567Z' // Too many decimal places
+      ];
+
+      validTimestamps.forEach(timestamp => {
+        expect(GTime.is_iso_format(timestamp)).toBe(true);
+      });
+
+      invalidTimestamps.forEach(timestamp => {
+        expect(GTime.is_iso_format(timestamp)).toBe(false);
+      });
+    });
+
+    test('should handle null and undefined', () => {
+      expect(GTime.is_iso_format(null)).toBe(false);
+      expect(GTime.is_iso_format(undefined)).toBe(false);
+    });
+  });
+
+  describe('stamp_now (alias)', () => {
+    test('should be an alias for stampNow', () => {
+      // We can't compare exact timestamps due to microsecond differences
+      const stampNowResult = GTime.stampNow();
+      const stampNowAliasResult = GTime.stamp_now();
+      
+      expect(stampNowResult.split('|')[0]).toBe(stampNowAliasResult.split('|')[0]);
+      expect(stampNowResult.split('|')[2]).toBe(stampNowAliasResult.split('|')[2]);
+    });
+  });
+});
diff --git a/src/test/sqlite_engine.test.js b/src/test/sqlite_engine.test.js
index 2282c0c..bdb26ef 100644
--- a/src/test/sqlite_engine.test.js
+++ b/src/test/sqlite_engine.test.js
@@ -1,5 +1,6 @@
 import { SQLiteEngine, SQLiteConnection } from 'src/engine/sqlite_engine.js';
 import { MCardFromData } from 'src/content/model/mcard.js';
+import { GTime } from 'src/content/model/g_time.js';
 import fs from 'fs';
 import path from 'path';
 
@@ -16,13 +17,14 @@ describe('SQLiteEngine', () => {
     sqliteEngine = new SQLiteEngine(connection);
 
     // Create a test card
+    const timestamp = GTime.stampNow();
     testCard = new MCardFromData(
-      JSON.stringify({ 
+      Buffer.from(JSON.stringify({ 
         title: 'Test Card', 
         content: 'This is a test card content' 
-      }), 
+      })), 
       'test_hash_123', 
-      Date.now()
+      timestamp
     );
   });
 
@@ -48,7 +50,7 @@ describe('SQLiteEngine', () => {
     
     expect(retrievedCard).toBeTruthy();
     expect(retrievedCard.hash).toBe(testCard.hash);
-    expect(retrievedCard.content).toBe(testCard.content);
+    expect(retrievedCard.content).toEqual(testCard.content);
   });
 
   test('should return null when retrieving non-existent card', () => {
@@ -69,9 +71,9 @@ describe('SQLiteEngine', () => {
   test('should get paginated results', () => {
     // Add multiple cards
     const cards = [
-      new MCardFromData(JSON.stringify({ title: 'Card 1' }), 'hash1', Date.now()),
-      new MCardFromData(JSON.stringify({ title: 'Card 2' }), 'hash2', Date.now()),
-      new MCardFromData(JSON.stringify({ title: 'Card 3' }), 'hash3', Date.now())
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 1' })), 'hash1', GTime.stampNow()),
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 2' })), 'hash2', GTime.stampNow()),
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 3' })), 'hash3', GTime.stampNow())
     ];
 
     cards.forEach(card => sqliteEngine.add(card));
@@ -88,8 +90,8 @@ describe('SQLiteEngine', () => {
   test('should search cards by string', () => {
     // Add multiple cards with different content
     const cards = [
-      new MCardFromData(JSON.stringify({ title: 'Search Test Card 1', content: 'First test card' }), 'hash1', Date.now()),
-      new MCardFromData(JSON.stringify({ title: 'Search Test Card 2', content: 'Second test card' }), 'hash2', Date.now())
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Search Test Card 1', content: 'First test card' })), 'hash1', GTime.stampNow()),
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Search Test Card 2', content: 'Second test card' })), 'hash2', GTime.stampNow())
     ];
 
     cards.forEach(card => sqliteEngine.add(card));
@@ -103,8 +105,8 @@ describe('SQLiteEngine', () => {
   test('should count total cards', () => {
     // Add multiple cards
     const cards = [
-      new MCardFromData(JSON.stringify({ title: 'Card 1' }), 'hash1', Date.now()),
-      new MCardFromData(JSON.stringify({ title: 'Card 2' }), 'hash2', Date.now())
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 1' })), 'hash1', GTime.stampNow()),
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 2' })), 'hash2', GTime.stampNow())
     ];
 
     cards.forEach(card => sqliteEngine.add(card));
@@ -144,9 +146,9 @@ describe('SQLiteEngine', () => {
   test('should get all cards', () => {
     // Add multiple cards
     const cards = [
-      new MCardFromData(JSON.stringify({ title: 'Card 1' }), 'hash1', Date.now()),
-      new MCardFromData(JSON.stringify({ title: 'Card 2' }), 'hash2', Date.now()),
-      new MCardFromData(JSON.stringify({ title: 'Card 3' }), 'hash3', Date.now())
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 1' })), 'hash1', GTime.stampNow()),
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 2' })), 'hash2', GTime.stampNow()),
+      new MCardFromData(Buffer.from(JSON.stringify({ title: 'Card 3' })), 'hash3', GTime.stampNow())
     ];
 
     cards.forEach(card => sqliteEngine.add(card));
diff --git a/src/test/test_cards.sqlite b/src/test/test_cards.sqlite
new file mode 100644
index 0000000..13b3f18
Binary files /dev/null and b/src/test/test_cards.sqlite differ

commit 0eb6656f80e5cfbb17536f7068e1e3cd1691c94f
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 17:40:05 2025 +0800

    new file locations

diff --git a/.env.sqlite b/.env.sqlite
new file mode 100644
index 0000000..de48863
--- /dev/null
+++ b/.env.sqlite
@@ -0,0 +1,20 @@
+# SQLite Database Configuration
+
+# Path to the SQLite database file
+MCARD_DB_PATH=public/data/cards.db
+
+# Hash algorithm for generating unique identifiers
+# Options: md5, sha1, sha224, sha256, sha384, sha512
+MCARD_HASH_ALGORITHM=md5
+
+# Length of the generated hash (32 for MD5)
+DEFAULT_HASH_LENGTH=32
+
+# Logging level
+LOG_LEVEL=info
+
+# Default page size for pagination
+DEFAULT_PAGE_SIZE=10
+
+# Path to test database file
+TEST_DB_PATH=src/test/data/db/test.db
diff --git a/package.json b/package.json
index 8854654..bfb5d28 100644
--- a/package.json
+++ b/package.json
@@ -19,6 +19,7 @@
     "astro": "^5.3.0",
     "class-variance-authority": "^0.7.0",
     "classnames": "^2.3.1",
+    "dotenv": "^16.4.7",
     "jimp": "^0.22.8",
     "lucide-react": "^0.284.0",
     "react": "^18.2.0",
diff --git a/src/content/model/card-collection.js b/src/content/model/card-collection.js
index 5383237..eb89e3f 100644
--- a/src/content/model/card-collection.js
+++ b/src/content/model/card-collection.js
@@ -3,8 +3,8 @@ import {
   generateDuplicationEvent, 
   generateCollisionEvent
 } from './event-producer.js';
-import logger from '../services/logger.js';
-import { DEFAULT_PAGE_SIZE, HASH_ALGORITHM_HIERARCHY, HashAlgorithm } from '../config/config_constants.js';
+import logger from '../../services/logger.js';
+import { DEFAULT_PAGE_SIZE, HASH_ALGORITHM_HIERARCHY, HashAlgorithm } from '../../config/config_constants.js';
 import HashValidator from './hash/validator.js';
 
 console.log('Card Collection Module Loading...');
diff --git a/src/content/model/event-producer.js b/src/content/model/event-producer.js
index 625684d..2faa2cc 100644
--- a/src/content/model/event-producer.js
+++ b/src/content/model/event-producer.js
@@ -1,7 +1,7 @@
 import HashAlgorithmEnum from './hash/enums.js';
 import HashValidator from './hash/validator.js';
 import { GTime as GTimeUtil } from './g_time.js';
-import { HASH_ALGORITHM_HIERARCHY as ALGORITHM_HIERARCHY } from '../config/config_constants.js';
+import { HASH_ALGORITHM_HIERARCHY as ALGORITHM_HIERARCHY } from '../../config/config_constants.js';
 
 // Destructure the enum values
 const { 
diff --git a/src/content/model/g_time.js b/src/content/model/g_time.js
index dd61761..c4c5c46 100644
--- a/src/content/model/g_time.js
+++ b/src/content/model/g_time.js
@@ -1,4 +1,4 @@
-import { HashAlgorithm } from '../config/config_constants.js';
+import { HashAlgorithm } from '../../config/config_constants.js';
 
 export class GTime {
   /**
diff --git a/src/content/model/hash/enums.js b/src/content/model/hash/enums.js
index cfa1fb9..08acd2f 100644
--- a/src/content/model/hash/enums.js
+++ b/src/content/model/hash/enums.js
@@ -1,49 +1,70 @@
 import crypto from 'crypto';
-import { HashAlgorithm, HashAlgorithmMetadata } from '../../config/config_constants.js';
+import { HashAlgorithm, HashAlgorithmMetadata } from '../../../config/config_constants.js';
 
 /**
  * Create a function to get hash algorithm details
- * @param {string} algorithm - Hash algorithm value
- * @returns {Object} Hash algorithm details
+ * @param {string} algorithm - Hash algorithm to get details for
+ * @returns {Object} Details of the hash algorithm
  */
-const getAlgorithmDetails = (algorithm) => {
-  const normalizedAlgo = algorithm.toLowerCase();
-  const algorithmDetails = Object.values(HashAlgorithmMetadata)
-    .find(algo => algo.value === normalizedAlgo);
-  
-  if (!algorithmDetails) {
-    throw new Error(`Unsupported hash algorithm: ${algorithm}`);
-  }
-  
-  return algorithmDetails;
-};
+export function getHashAlgorithmDetails(algorithm) {
+  const normalizedAlgorithm = HashAlgorithm(algorithm);
+  return HashAlgorithmMetadata[normalizedAlgorithm] || null;
+}
 
 /**
- * Compute hash for given content using specified algorithm
- * @param {Uint8Array} content - Content to hash
- * @param {string} algorithm - Hash algorithm
- * @returns {string} Computed hash
+ * Get the output length of a hash algorithm
+ * @param {string} algorithm - Hash algorithm to get output length for
+ * @returns {number} Output length of the hash algorithm
  */
-const hash = (content, algorithm) => {
-  const hash = crypto.createHash(algorithm.toLowerCase());
-  hash.update(content);
-  return hash.digest('hex');
-};
+export function getHashOutputLength(algorithm) {
+  const details = getHashAlgorithmDetails(algorithm);
+  return details ? details.outputLength : 64; // Default to 64 if not found
+}
+
+/**
+ * Check if a hash algorithm is the default
+ * @param {string} algorithm - Hash algorithm to check
+ * @returns {boolean} Whether the algorithm is the default
+ */
+export function isDefaultHashAlgorithm(algorithm) {
+  const details = getHashAlgorithmDetails(algorithm);
+  return details ? details.isDefault : false;
+}
 
-// Utility function for hash generation
-const generateHash = (input, algorithm = HashAlgorithm.DEFAULT) => {
-  const hash = crypto.createHash(algorithm);
+/**
+ * Generate a hash using a specified algorithm
+ * @param {string} input - Input to hash
+ * @param {string} [algorithm] - Hash algorithm to use
+ * @returns {string} Generated hash
+ */
+export function generateHash(input, algorithm = HashAlgorithm.DEFAULT) {
+  const normalizedAlgorithm = HashAlgorithm(algorithm);
+  const hash = crypto.createHash(normalizedAlgorithm);
   hash.update(input);
   return hash.digest('hex');
-};
+}
 
-// Correct way to do a default export
-const HashAlgorithmEnum = {
-  HashAlgorithm,
-  HashAlgorithmMetadata,
-  getAlgorithmDetails,
-  hash,
-  generateHash
-};
+/**
+ * Validate a hash against its algorithm
+ * @param {string} hash - Hash to validate
+ * @param {string} algorithm - Hash algorithm to validate against
+ * @returns {boolean} Whether the hash is valid
+ */
+export function validateHash(hash, algorithm) {
+  const details = getHashAlgorithmDetails(algorithm);
+  if (!details) return false;
 
-export default HashAlgorithmEnum;  // This is the key line
+  // Check hash length
+  if (hash.length !== details.outputLength) return false;
+
+  // Check if hash contains only hexadecimal characters
+  return /^[0-9a-fA-F]+$/.test(hash);
+}
+
+export default {
+  getHashAlgorithmDetails,
+  getHashOutputLength,
+  isDefaultHashAlgorithm,
+  generateHash,
+  validateHash
+};
diff --git a/src/content/model/hash/validator.js b/src/content/model/hash/validator.js
index aea80ae..f946969 100644
--- a/src/content/model/hash/validator.js
+++ b/src/content/model/hash/validator.js
@@ -4,7 +4,7 @@ import {
   HashAlgorithm, 
   HASH_ALGORITHM_HIERARCHY, 
   VALID_HASH_FUNCTIONS 
-} from '../../config/config_constants.js';
+} from '../../../config/config_constants.js';
 
 export default class HashValidator {
   /**
diff --git a/src/content/model/mcard.js b/src/content/model/mcard.js
index a3061fc..8c0d57c 100644
--- a/src/content/model/mcard.js
+++ b/src/content/model/mcard.js
@@ -1,6 +1,6 @@
 import { Buffer } from 'buffer';
 import GTime from './g_time.js';
-import { HashAlgorithm } from '../config/config_constants.js';
+import { HashAlgorithm } from '../../config/config_constants.js';
 import HashValidator from './hash/validator.js';
 import ContentTypeInterpreter from './content_type_detector.js';
 
diff --git a/src/engine/sqlite_engine.js b/src/engine/sqlite_engine.js
index 9d42617..3a8dc0c 100644
--- a/src/engine/sqlite_engine.js
+++ b/src/engine/sqlite_engine.js
@@ -1,6 +1,5 @@
-import log from 'src/services/logger.js';
 import { MCardFromData } from 'src/content/model/mcard.js';
-import { Page } from 'src/models/card-collection.js';
+import { Page } from 'src/content/model/card-collection.js';
 import { DEFAULT_PAGE_SIZE, CARDS_DB_PATH } from 'src/config/config_constants.js';
 import { MCARD_TABLE_SCHEMA, TRIGGERS } from 'src/models/database_schemas.js';
 import { promises as fs } from 'fs';
@@ -50,9 +49,9 @@ class SQLiteConnection {
         this.conn.prepare(trigger).run();
       });
 
-      log.debug(`Database setup complete at ${this.dbPath}`);
+      console.log(`Database setup complete at ${this.dbPath}`);
     } catch (error) {
-      log.error(`Error setting up database: ${error.message}`);
+      console.error(`Error setting up database: ${error.message}`);
       throw error;
     }
   }
@@ -62,11 +61,11 @@ class SQLiteConnection {
    */
   connect() {
     if (!this.conn) {
-      log.debug(`Connecting to database at ${this.dbPath}`);
+      console.log(`Connecting to database at ${this.dbPath}`);
       try {
         this.conn = new Database(this.dbPath);
-        log.debug(`Connection established to ${this.dbPath}`);
-        log.debug(`Database connection details: ${this.conn}`);
+        console.log(`Connection established to ${this.dbPath}`);
+        console.log(`Database connection details: ${this.conn}`);
 
         // Check if the database is empty and initialize schema if necessary
         const tablesStmt = this.conn.prepare("SELECT name FROM sqlite_master WHERE type='table'");
@@ -79,20 +78,20 @@ class SQLiteConnection {
 
           // Create tables from schema
           Object.entries(MCARD_TABLE_SCHEMA).forEach(([tableName, schema]) => {
-            log.info(`Executing SQL for ${tableName}: ${schema}`);
+            console.log(`Executing SQL for ${tableName}: ${schema}`);
             this.conn.prepare(schema).run();
           });
 
-          log.debug("Database schema created successfully");
+          console.log("Database schema created successfully");
 
           // Create triggers
           TRIGGERS.forEach((trigger) => {
-            log.info(`Executing SQL trigger: ${trigger}`);
+            console.log(`Executing SQL trigger: ${trigger}`);
             this.conn.prepare(trigger).run();
           });
         }
       } catch (error) {
-        log.error(`Database error connecting to ${this.dbPath}: ${error.message}`);
+        console.error(`Database error connecting to ${this.dbPath}: ${error.message}`);
         throw error;
       }
     }
@@ -105,7 +104,7 @@ class SQLiteConnection {
     if (this.conn) {
       this.conn.close();
       this.conn = null;
-      log.debug('Database connection closed');
+      console.log('Database connection closed');
     }
   }
 
@@ -170,13 +169,13 @@ class SQLiteEngine {
         card.g_time
       );
 
-      log.debug(`Added card with hash ${card.hash}`);
+      console.log(`Added card with hash ${card.hash}`);
       return String(card.hash);
     } catch (error) {
       if (error.code === 'SQLITE_CONSTRAINT') {
         throw new Error(`Card with hash ${card.hash} already exists`);
       }
-      log.error(`Error adding card: ${error.message}`);
+      console.error(`Error adding card: ${error.message}`);
       throw error;
     }
   }
@@ -198,7 +197,7 @@ class SQLiteEngine {
       
       return new MCardFromData(row.content, row.hash, row.g_time);
     } catch (error) {
-      log.error(`Error retrieving card: ${error.message}`);
+      console.error(`Error retrieving card: ${error.message}`);
       throw error;
     }
   }
@@ -217,7 +216,7 @@ class SQLiteEngine {
       const result = stmt.run(String(hashValue));
       return result.changes > 0;
     } catch (error) {
-      log.error(`Error deleting card: ${error.message}`);
+      console.error(`Error deleting card: ${error.message}`);
       throw error;
     }
   }
@@ -293,7 +292,7 @@ class SQLiteEngine {
       const cursor = this.connection.conn;
 
       // Debug: Log the search parameters
-      log.info(`Searching with string: ${searchString}, Page: ${pageNumber}, PageSize: ${pageSize}`);
+      console.log(`Searching with string: ${searchString}, Page: ${pageNumber}, PageSize: ${pageSize}`);
 
       // First, get total count of matching items
       const countStmt = cursor.prepare(`
@@ -310,7 +309,7 @@ class SQLiteEngine {
       );
 
       // Debug: Log the total count
-      log.info(`Total matching items: ${total}`);
+      console.log(`Total matching items: ${total}`);
 
       // Then, get the actual items for the current page
       const stmt = cursor.prepare(`
@@ -331,7 +330,7 @@ class SQLiteEngine {
       );
 
       // Debug: Log the rows
-      log.info(`Matching rows: ${JSON.stringify(rows)}`);
+      console.log(`Matching rows: ${JSON.stringify(rows)}`);
 
       // Convert rows to cards
       const items = [];
@@ -355,7 +354,7 @@ class SQLiteEngine {
         total_pages: Math.ceil(total / pageSize)
       });
     } catch (error) {
-      log.error(`Error searching cards: ${error.message}`);
+      console.error(`Error searching cards: ${error.message}`);
       throw error;
     }
   }
@@ -420,7 +419,7 @@ class SQLiteEngine {
         total_pages: Math.ceil(total / pageSize)
       });
     } catch (error) {
-      log.error(`Error searching cards: ${error.message}`);
+      console.error(`Error searching cards: ${error.message}`);
       throw error;
     }
   }
diff --git a/src/services/logger.js b/src/services/logger.js
new file mode 100644
index 0000000..3846080
--- /dev/null
+++ b/src/services/logger.js
@@ -0,0 +1,74 @@
+/**
+ * Simple logging service with configurable log levels
+ */
+class Logger {
+  /**
+   * Create a new logger instance
+   * @param {string} [level='info'] - Logging level
+   */
+  constructor(level = 'info') {
+    this.level = level.toLowerCase();
+    this.levels = ['error', 'warn', 'info', 'debug'];
+  }
+
+  /**
+   * Check if a log level is enabled
+   * @param {string} level - Log level to check
+   * @returns {boolean} Whether the log level is enabled
+   */
+  isLevelEnabled(level) {
+    const currentLevelIndex = this.levels.indexOf(this.level);
+    const checkLevelIndex = this.levels.indexOf(level);
+    return checkLevelIndex <= currentLevelIndex;
+  }
+
+  /**
+   * Log an error message
+   * @param {string} message - Message to log
+   * @param {Object} [metadata] - Optional metadata
+   */
+  error(message, metadata = {}) {
+    if (this.isLevelEnabled('error')) {
+      console.error(`[ERROR] ${message}`, metadata);
+    }
+  }
+
+  /**
+   * Log a warning message
+   * @param {string} message - Message to log
+   * @param {Object} [metadata] - Optional metadata
+   */
+  warn(message, metadata = {}) {
+    if (this.isLevelEnabled('warn')) {
+      console.warn(`[WARN] ${message}`, metadata);
+    }
+  }
+
+  /**
+   * Log an info message
+   * @param {string} message - Message to log
+   * @param {Object} [metadata] - Optional metadata
+   */
+  info(message, metadata = {}) {
+    if (this.isLevelEnabled('info')) {
+      console.log(`[INFO] ${message}`, metadata);
+    }
+  }
+
+  /**
+   * Log a debug message
+   * @param {string} message - Message to log
+   * @param {Object} [metadata] - Optional metadata
+   */
+  debug(message, metadata = {}) {
+    if (this.isLevelEnabled('debug')) {
+      console.debug(`[DEBUG] ${message}`, metadata);
+    }
+  }
+}
+
+// Create a default logger instance using environment variable
+const logger = new Logger(process.env.LOG_LEVEL || 'info');
+
+export default logger;
+export { Logger };
diff --git a/src/test/sqlite_engine.test.js b/src/test/sqlite_engine.test.js
index 9ba8cc5..2282c0c 100644
--- a/src/test/sqlite_engine.test.js
+++ b/src/test/sqlite_engine.test.js
@@ -122,6 +122,7 @@ describe('SQLiteEngine', () => {
       const retrievedCard = sqliteEngine.get(testCard.hash);
       expect(retrievedCard).toBeNull();
     } catch (error) {
+      console.log('Transaction rollback failed:', error);
       fail('Transaction rollback failed');
     }
   });
@@ -135,6 +136,7 @@ describe('SQLiteEngine', () => {
       const retrievedCard = sqliteEngine.get(testCard.hash);
       expect(retrievedCard).toBeTruthy();
     } catch (error) {
+      console.log('Transaction commit failed:', error);
       fail('Transaction commit failed');
     }
   });

commit 228af97b409ea2494845e51f4f64b0e3e7c5f51b
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 17:13:00 2025 +0800

    fixing issues

diff --git a/jest-resolver.cjs b/jest-resolver.cjs
new file mode 100644
index 0000000..992339a
--- /dev/null
+++ b/jest-resolver.cjs
@@ -0,0 +1,28 @@
+const path = require('path');
+const fs = require('fs');
+
+function resolveModule(request, options) {
+  // Handle src imports
+  if (request.startsWith('src/')) {
+    const rootDir = options.rootDir;
+    const fullPath = path.resolve(rootDir, request);
+    
+    // Check .js and .mjs extensions
+    const jsPath = fullPath.endsWith('.js') ? fullPath : `${fullPath}.js`;
+    const mjsPath = fullPath.endsWith('.mjs') ? fullPath : `${fullPath}.mjs`;
+    
+    if (fs.existsSync(jsPath)) return jsPath;
+    if (fs.existsSync(mjsPath)) return mjsPath;
+    
+    // Fallback to original path
+    return fullPath;
+  }
+  
+  // Default resolver
+  return options.defaultResolver(request, options);
+}
+
+module.exports = {
+  sync: resolveModule,
+  async: resolveModule
+};
diff --git a/jest-resolver.js b/jest-resolver.js
new file mode 100644
index 0000000..42d4dc1
--- /dev/null
+++ b/jest-resolver.js
@@ -0,0 +1,16 @@
+import path from 'path';
+import { fileURLToPath } from 'url';
+
+const __filename = fileURLToPath(import.meta.url);
+const __dirname = path.dirname(__filename);
+
+export default function resolver(request, options) {
+  // Handle src imports
+  if (request.startsWith('src/')) {
+    const fullPath = path.resolve(__dirname, request);
+    return fullPath;
+  }
+  
+  // Default resolver
+  return options.defaultResolver(request, options);
+}
diff --git a/jest.config.js b/jest.config.js
index fd72584..6e3a77f 100644
--- a/jest.config.js
+++ b/jest.config.js
@@ -6,8 +6,9 @@ export default {
   testMatch: ['**/__tests__/**/*.js?(x)', '**/?(*.)+(spec|test).js?(x)'],
   extensionsToTreatAsEsm: ['.jsx'],
   moduleNameMapper: {
-    '^(\\.{1,2}/.*)\\.js$': '$1'
+    '^src/(.*)$': '<rootDir>/src/$1'
   },
+  resolver: '<rootDir>/jest-resolver.cjs',
   transformIgnorePatterns: [
     'node_modules/(?!(@astrojs)/)'
   ]
diff --git a/package.json b/package.json
index 46ba98d..1f8225d 100644
--- a/package.json
+++ b/package.json
@@ -33,11 +33,13 @@
     "tailwindcss-animate": "^1.0.7"
   },
   "devDependencies": {
+    "@babel/preset-env": "^7.26.9",
     "@babel/preset-react": "^7.26.3",
     "@tailwindcss/typography": "^0.5.10",
     "@types/react": "^18.2.21",
     "@vite-pwa/astro": "^0.5.0",
     "autoprefixer": "^10.4.15",
+    "babel-jest": "^29.7.0",
     "jest": "^29.5.0",
     "jest-environment-jsdom": "^29.7.0",
     "postcss": "^8.4.29",

commit 4c5ca31c401a68d00dd93523d92df00fd199d58d
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 17:12:53 2025 +0800

    fixing issues

diff --git a/Docs/to-do-plan b/Docs/to-do-plan
index 90fe50e..7735a8f 160000
--- a/Docs/to-do-plan
+++ b/Docs/to-do-plan
@@ -1 +1 @@
-Subproject commit 90fe50ef320b6e2833810f558182966f5ac0ec8f
+Subproject commit 7735a8f83115b5baa70eb9ff594231785e5d3041

commit 4a84497187a983dc7b2a217066f558bc1d0f2dc0
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 17:00:06 2025 +0800

    passing test 5/6

diff --git a/package.json b/package.json
index e4f45dc..46ba98d 100644
--- a/package.json
+++ b/package.json
@@ -33,11 +33,13 @@
     "tailwindcss-animate": "^1.0.7"
   },
   "devDependencies": {
+    "@babel/preset-react": "^7.26.3",
     "@tailwindcss/typography": "^0.5.10",
     "@types/react": "^18.2.21",
     "@vite-pwa/astro": "^0.5.0",
     "autoprefixer": "^10.4.15",
     "jest": "^29.5.0",
+    "jest-environment-jsdom": "^29.7.0",
     "postcss": "^8.4.29",
     "tailwindcss": "^3.3.3"
   }

commit bea433a3f2a3c98678770c7d991b3831f4170f76
Author: Henrykoo <lckoo1230@gmail.com>
Date:   Tue Mar 18 16:39:16 2025 +0800

    mvoing sqlite_engine.test.js

diff --git a/tests/sqlite_engine.test.js b/src/test/sqlite_engine.test.js
similarity index 100%
rename from tests/sqlite_engine.test.js
rename to src/test/sqlite_engine.test.js
```
